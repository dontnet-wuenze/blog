{"meta":{"version":1,"warehouse":"4.0.1"},"models":{"Asset":[{"_id":"themes/fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":0,"renderable":1},{"_id":"themes/fluid/source/css/highlight-dark.styl","path":"css/highlight-dark.styl","modified":0,"renderable":1},{"_id":"themes/fluid/source/css/highlight.styl","path":"css/highlight.styl","modified":0,"renderable":1},{"_id":"themes/fluid/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/default.png","path":"img/default.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/fluid.png","path":"img/fluid.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/huiye.png","path":"img/huiye.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/loading.gif","path":"img/loading.gif","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/ling.png","path":"img/ling.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/nvpu.png","path":"img/nvpu.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/saber.png","path":"img/saber.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/smallsaber.png","path":"img/smallsaber.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/xiaomai.png","path":"img/xiaomai.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/background.js","path":"js/background.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/boot.js","path":"js/boot.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/firework.js","path":"js/firework.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/events.js","path":"js/events.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/plugins.js","path":"js/plugins.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/zaofan.jpg","path":"img/zaofan.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"source/_posts/hello-world.md","hash":"f602f8fd96eb4963458ecc9c25123b87377b3c40","modified":1657434123723},{"_id":"source/_posts/测试文章.md","hash":"7ae8320c0c21366f4441b1934737ed218b672998","modified":1657380406168},{"_id":"source/_posts/test.md","hash":"6923be2719c6a38afac094ed42e25288285b60ac","modified":1657466617356},{"_id":"source/about/index.md","hash":"0c591824c4cb4f0ec8bb717b273016f50282cd9f","modified":1657379886141},{"_id":"source/test/index.md","hash":"5a8aa2b686a44f0edf24a90bba426472f027e3f0","modified":1657422421585},{"_id":"themes/fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1655372397000},{"_id":"themes/fluid/.editorconfig","hash":"33218fbd623feb43edf5f99f15965392cecc44a6","modified":1655372397000},{"_id":"themes/fluid/.eslintrc","hash":"4bc2b19ce2b8c4d242f97d4ccf2d741e68ab0097","modified":1655372397000},{"_id":"themes/fluid/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":1655372397000},{"_id":"themes/fluid/.gitignore","hash":"ae3bfcb89777657c5dfb5169d91445dcb0e5ab98","modified":1655372397000},{"_id":"themes/fluid/LICENSE","hash":"26f9356fd6e84b5a88df6d9014378f41b65ba209","modified":1655372397000},{"_id":"themes/fluid/README_en.md","hash":"8c874f309e346fffa392e174385b5cc08510f218","modified":1655372397000},{"_id":"themes/fluid/README.md","hash":"6d752df6f2278033dc2512a7d5be22c8a8eb665a","modified":1655372397000},{"_id":"themes/fluid/_config.yml","hash":"d85e3ca607c1dc458137d54350cf45dba9915dd5","modified":1657529945631},{"_id":"themes/fluid/package.json","hash":"0bc354a01c5e6e9de43bf67456dc16c59d400139","modified":1655372397000},{"_id":"themes/fluid/layout/about.ejs","hash":"163bee643e6a38912d3ae70923c83c48d57222e7","modified":1655372397000},{"_id":"themes/fluid/layout/404.ejs","hash":"9569c5c8f67d2783f372f671c57b93a00dc63c2f","modified":1655372397000},{"_id":"themes/fluid/layout/archive.ejs","hash":"7c1f44005849791feae4abaa10fae4cb983d3277","modified":1655372397000},{"_id":"themes/fluid/layout/categories.ejs","hash":"13859726c27b6c79b5876ec174176d0f9c1ee164","modified":1655372397000},{"_id":"themes/fluid/layout/index.ejs","hash":"b15d13877827e99e0ff783a6b13b13cca90bfe8c","modified":1655372397000},{"_id":"themes/fluid/layout/category.ejs","hash":"f099161b738a16a32253f42085b5444f902018ed","modified":1655372397000},{"_id":"themes/fluid/layout/layout.ejs","hash":"1eb652467f4508f19ad1a2937d0fde51bcbc7118","modified":1657621817459},{"_id":"themes/fluid/layout/links.ejs","hash":"1cac32ec4579aaf7b9fa39d317497331d4c5e1dd","modified":1655372397000},{"_id":"themes/fluid/layout/page.ejs","hash":"ed5007a3feb8f14d3d2843271bfb298eb0c56219","modified":1655372397000},{"_id":"themes/fluid/layout/tag.ejs","hash":"9d686364c4d16a1a9219471623af452035c5b966","modified":1655372397000},{"_id":"themes/fluid/layout/post.ejs","hash":"505bcc06e55066b7cc5551d9ac0694e7713bfab5","modified":1655372397000},{"_id":"themes/fluid/layout/tags.ejs","hash":"1d06af34b6cf1d8a20d2eb565e309326ceba309f","modified":1655372397000},{"_id":"themes/fluid/languages/de.yml","hash":"0e7d455d9e004ff15d8924b7a0c35cea25ee5b1d","modified":1655372397000},{"_id":"themes/fluid/languages/en.yml","hash":"cb11b39f44ea069652c9647179606b6cecc98d50","modified":1655372397000},{"_id":"themes/fluid/languages/eo.yml","hash":"a556251cc50a5680578c03f1efbf252b1f4ab860","modified":1655372397000},{"_id":"themes/fluid/languages/ja.yml","hash":"3dd6d20f8d26585a7c154a8e59fe8d5d902f4c6a","modified":1655372397000},{"_id":"themes/fluid/languages/es.yml","hash":"7112594259c88c04714be152af7fd377687dad40","modified":1655372397000},{"_id":"themes/fluid/languages/zh-CN.yml","hash":"f96a22f989897ecddc69d5867a206e1cf6b8f610","modified":1655372397000},{"_id":"themes/fluid/languages/zh-TW.yml","hash":"596d031dff3826ae8e4ffc8931fff28977b73247","modified":1655372397000},{"_id":"themes/fluid/languages/zh-HK.yml","hash":"80ed400a7adaa92ea54fc7f5d534c9af795bed00","modified":1655372397000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report_zh.md","hash":"af977ed0792508bb0766ea8afe82d34ef1e8fb3c","modified":1655372397000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report.md","hash":"16d33eb89ecf90f4046720fde5395d972c7ba1fd","modified":1655372397000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request.md","hash":"c134dd57ffd269b93402ccfffe7dbe0f0b583bec","modified":1655372397000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question_zh.md","hash":"e24b470f7aa8044499a4f5e39634e5dc43899011","modified":1655372397000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request_zh.md","hash":"ed08574b196447376dd74411cca664ac9227a5d4","modified":1655372397000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question.md","hash":"ab5eab9e3ff889c4ba7fd82846e7f5b7ae15bebc","modified":1655372397000},{"_id":"themes/fluid/.github/workflows/limit.yaml","hash":"f8bd2edeb4424ee7a055b31583445d5d5dff91a4","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/archive-list.ejs","hash":"7520fbf91f762207c2ab06b2c293235cd5b23905","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/category-chains.ejs","hash":"18309584aab83bc4deb20723ebad832149dd2e24","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/category-list.ejs","hash":"a591fedbc5759fb00152304f9ea486dfba3a246a","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/comments.ejs","hash":"24ef242aa01e5f5bc397cf3f83ae48b1e8353dab","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/footer.ejs","hash":"10ccfb8eef4e16182183c9a3e175c90d5b6397d3","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/css.ejs","hash":"85f6e051550907681ab4ed2e268ac8f6e9ebf931","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/head.ejs","hash":"776949aa697dffd54e9b1957d9245028879509a3","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/markdown-plugins.ejs","hash":"fc4bdf7de0cf1a66d0e5e4fba1b31d6f7ed49468","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/paginator.ejs","hash":"0f38a2c238169edcb63fc46c23bfc529ff3859b7","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/header.ejs","hash":"0d5e397d30051e5fbabe7b47cfd1f1e6a5820af1","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/search.ejs","hash":"70e1c929e084ca8a2648cedabf29b372511ea2b8","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/scripts.ejs","hash":"da5810785105e5075861593c7ac22c7aa9665a72","modified":1655372397000},{"_id":"themes/fluid/scripts/events/index.js","hash":"79de5a379b28cad759a49048351c7f6b8915bd7d","modified":1655372397000},{"_id":"themes/fluid/scripts/filters/default-injects.js","hash":"b2013ae8e189cd07ebc8a2ff48a78e153345210f","modified":1655372397000},{"_id":"themes/fluid/scripts/filters/locals.js","hash":"58d0fec976f6b1d35e7ea03edc45414088acf05c","modified":1655372397000},{"_id":"themes/fluid/scripts/filters/post-filter.js","hash":"d516b9db63067f9ea9c72cc75ae4ff358417e77d","modified":1655372397000},{"_id":"themes/fluid/scripts/generators/local-search.js","hash":"fc2c50405b771b06b7f6cfc4e9de97b992691555","modified":1655372397000},{"_id":"themes/fluid/scripts/generators/pages.js","hash":"d9971f15fbb6b775e3d31a1b9b45011959395010","modified":1655372397000},{"_id":"themes/fluid/scripts/tags/button.js","hash":"3eb43a8cdea0a64576ad6b31b4df6c2bf5698d4c","modified":1655372397000},{"_id":"themes/fluid/scripts/tags/checkbox.js","hash":"4938610c3543a921a341bc074626d511cb1a4b45","modified":1655372397000},{"_id":"themes/fluid/scripts/tags/group-image.js","hash":"4aeebb797026f1df25646a5d69f7fde79b1bcd26","modified":1655372397000},{"_id":"themes/fluid/scripts/tags/mermaid.js","hash":"75160561e1ef3603b6d2ad2938464ab1cb77fd38","modified":1655372397000},{"_id":"themes/fluid/scripts/tags/label.js","hash":"f05a6d32cca79535b22907dc03edb9d3fa2d8176","modified":1655372397000},{"_id":"themes/fluid/scripts/helpers/date.js","hash":"9bda6382f61b40a20c24af466fe10c8366ebb74c","modified":1655372397000},{"_id":"themes/fluid/scripts/tags/note.js","hash":"f52f3a005b41f48b4da274ac64710177c8d4502f","modified":1655372397000},{"_id":"themes/fluid/scripts/helpers/engine.js","hash":"d3a231d106795ce99cb0bc77eb65f9ae44515933","modified":1655372397000},{"_id":"themes/fluid/scripts/helpers/import.js","hash":"ca53e8dbf7d44cfd372cfa79ac60f35a7d5b0076","modified":1655372397000},{"_id":"themes/fluid/scripts/helpers/export-config.js","hash":"47e6dba7652a621a54067413490a11c8a89e3d7b","modified":1655372397000},{"_id":"themes/fluid/scripts/helpers/page.js","hash":"4607607445233b3029ef20ed5e91de0da0a7f9c5","modified":1655372397000},{"_id":"themes/fluid/scripts/helpers/injects.js","hash":"1ad2ae6b11bd8806ee7dd6eb7140d8b54a95d613","modified":1655372397000},{"_id":"themes/fluid/scripts/helpers/scope.js","hash":"43620b0944ffb67ea1fa6cc838f65a7351222eb0","modified":1655372397000},{"_id":"themes/fluid/scripts/helpers/url.js","hash":"2a6a8288176d0e0f6ec008056bf2745a86e8943e","modified":1655372397000},{"_id":"themes/fluid/scripts/helpers/utils.js","hash":"226f99b465ff513de075a8e78b321d6cb62592ca","modified":1655372397000},{"_id":"themes/fluid/scripts/helpers/wordcount.js","hash":"b917b893b1777e6ffcb53188f9f5644510e5f20d","modified":1655372397000},{"_id":"themes/fluid/scripts/utils/compare-versions.js","hash":"dbbc928c914fc2bd242cd66aa0c45971aec13a5d","modified":1655372397000},{"_id":"themes/fluid/scripts/utils/resolve.js","hash":"8c4a8b62aa8608f12f1e9046231dff04859dc3e9","modified":1655372397000},{"_id":"themes/fluid/scripts/utils/url-join.js","hash":"718aab5e7b2059a06b093ca738de420d9afa44ba","modified":1655372397000},{"_id":"themes/fluid/scripts/utils/object.js","hash":"33b57e4decdc5e75c518859f168c8ba80b2c665b","modified":1655372397000},{"_id":"themes/fluid/source/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1655372397000},{"_id":"themes/fluid/source/css/highlight.styl","hash":"a9efc52a646a9e585439c768557e3e3c9e3326dc","modified":1655372397000},{"_id":"themes/fluid/source/css/highlight-dark.styl","hash":"45695ef75c31a4aa57324dd408b7e2327a337018","modified":1655372397000},{"_id":"themes/fluid/source/css/main.styl","hash":"855ae5fe229c51afa57f7645f6997a27a705d7e4","modified":1655372397000},{"_id":"themes/fluid/source/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1655372397000},{"_id":"themes/fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1655372397000},{"_id":"themes/fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1655372397000},{"_id":"themes/fluid/source/img/smallsaber.png","hash":"352be575db4326bd34eace19a3bfb472f360ba5c","modified":1657422969608},{"_id":"themes/fluid/source/js/background.js","hash":"8aa7bad39c479b9d228ec3f12a8ea0a6436a78cf","modified":1657340207768},{"_id":"themes/fluid/source/js/boot.js","hash":"2848f8eb5081a7f0550fbd76dc06d3ff877f1913","modified":1655372397000},{"_id":"themes/fluid/source/js/firework.js","hash":"3a6d39db05d9e719c69cf8c988a4678e35a96271","modified":1657340731981},{"_id":"themes/fluid/source/js/events.js","hash":"f05a569a9fd6da2fda69a2cf8e276ba81580faf3","modified":1655372397000},{"_id":"themes/fluid/source/js/color-schema.js","hash":"ba63f7c3324bc1fdd050a90add9d8faaffc27e07","modified":1655372397000},{"_id":"themes/fluid/source/js/local-search.js","hash":"cebcda5991b6a9ab9307c69542389ce9013f04f7","modified":1655372397000},{"_id":"themes/fluid/source/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1655372397000},{"_id":"themes/fluid/source/js/utils.js","hash":"45cc86f099db0a2c36ad49711ce66c2d598a2ab1","modified":1655372397000},{"_id":"themes/fluid/source/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1655372397000},{"_id":"themes/fluid/source/js/plugins.js","hash":"2333494add51e5e1374602a4e81f0be36a05d4c2","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/comments/changyan.ejs","hash":"c9b2d68ed3d375f1953e7007307d2a3f75ed6249","modified":1655372397000},{"_id":"themes/fluid/source/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/comments/cusdis.ejs","hash":"5f9dc012be27040bbe874d0c093c0d53958cc987","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/comments/disqus.ejs","hash":"aab4a4d24c55231a37db308ae94414319cecdd9b","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/comments/giscus.ejs","hash":"95f8b866b158eff9352c381c243b332a155a5110","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/comments/gitalk.ejs","hash":"843bc141a4545eb20d1c92fb63c85d459b4271ec","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/comments/livere.ejs","hash":"2264758fed57542a7389c7aa9f00f1aefa17eb87","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/comments/remark42.ejs","hash":"d4e9532feeb02aed61bd15eda536b5b631454dac","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/comments/twikoo.ejs","hash":"e6820fb7f13662c42f8433ec95404238f4c1860c","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/comments/utterances.ejs","hash":"c7ccf7f28308334a6da6f5425b141a24b5eca0e2","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/comments/valine.ejs","hash":"19ba937553dddd317f827d682661a1066a7b1f30","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/comments/waline.ejs","hash":"12727da7cf3ac83443270f550be4d1c06135b52b","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/footer/beian.ejs","hash":"4fb9b5dd3f3e41a586d6af44e5069afe7c81fff2","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/footer/statistics.ejs","hash":"454d8dd4c39f9494ebeb03ca0746f5bc122af76a","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/header/banner.ejs","hash":"e07757b59e7b89eea213d0e595cb5932f812fd32","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/header/navigation.ejs","hash":"38990ed9dbccd88342ee4b4cb5e60818e9eb8e8a","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/post/category-bar.ejs","hash":"88420e83c0968f7da69aa423f42d3033891c9229","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/post/copyright.ejs","hash":"e74fb49526ddb14fee2c6360a560d17f57262ef7","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/post/meta-bottom.ejs","hash":"7079b27a7bc15a7dfa9209f6be6051bdec49ebad","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/post/meta-top.ejs","hash":"ce6e9f578f4faa45840abddf8f46af3f4b69c177","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/post/sidebar-left.ejs","hash":"9992c99b3eb728ad195970e1b84d665f2c8691c4","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/post/sidebar-right.ejs","hash":"d5fcc9b60e02f869a29a8c17a16a6028ecc1e6d8","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/plugins/analytics.ejs","hash":"1327395a4dde1ea06c476b047fb110bcd269149f","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/post/toc.ejs","hash":"91a1de823492d9225f9daa3ef59efbca345456a0","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/plugins/anchorjs.ejs","hash":"953552425f0b86c98d1026fdb04e716fdff356e7","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/plugins/code-widget.ejs","hash":"3a505cba37942badf62a56bbb8b605b72af330aa","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/plugins/fancybox.ejs","hash":"9d1ea2a46b8c8ad8c168594d578f40764818ef13","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/plugins/encrypt.ejs","hash":"cbcf6905f4990a22895a848e29dd4c05592a9043","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/plugins/highlight.ejs","hash":"7529dd215b09d3557804333942377b9e20fa554e","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/plugins/math.ejs","hash":"94c1ce6e312932e876886ba24b082ae34515a038","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/plugins/nprogress.ejs","hash":"4c2d39ce816b8a6dcd6b53113c8695f8bd650a23","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/plugins/mermaid.ejs","hash":"3b3b0be9f7624ff72fbb2da6ae3663adcfb7d118","modified":1655372397000},{"_id":"themes/fluid/layout/_partials/plugins/typed.ejs","hash":"51faef29f8e464bcb2e73049b428b88c8dd8b40a","modified":1655372397000},{"_id":"themes/fluid/scripts/events/lib/compatible-configs.js","hash":"ef474d1fa5bbafc52619ced0f9dc7eaf2affb363","modified":1655372397000},{"_id":"themes/fluid/scripts/events/lib/footnote.js","hash":"2ec2ae03c79bb1ae7ac3fcf7e00fb52d1af2898d","modified":1655372397000},{"_id":"themes/fluid/scripts/events/lib/highlight.js","hash":"0f02df2244e275595e72163498d42f42bcf0de5e","modified":1655372397000},{"_id":"themes/fluid/scripts/events/lib/hello.js","hash":"44c5eb97b98813a07c659d6afedd17fad63b1821","modified":1655372397000},{"_id":"themes/fluid/scripts/events/lib/lazyload.js","hash":"9ba0d4bc224e22af8a5a48d6ff13e5a0fcfee2a4","modified":1655372397000},{"_id":"themes/fluid/scripts/events/lib/merge-configs.js","hash":"7c944c43b2ece5dd84859bd9d1fe955d13427387","modified":1655372397000},{"_id":"themes/fluid/scripts/events/lib/injects.js","hash":"5ae4b07204683e54b5a1b74e931702bbce2ac23e","modified":1655372397000},{"_id":"themes/fluid/source/css/_functions/base.styl","hash":"2e46f3f4e2c9fe34c1ff1c598738fc7349ae8188","modified":1655372397000},{"_id":"themes/fluid/source/css/_mixins/base.styl","hash":"542e306ee9494e8a78e44d6d7d409605d94caeb3","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/pages.styl","hash":"b8e887bc7fb3b765a1f8ec9448eff8603a41984f","modified":1655372397000},{"_id":"themes/fluid/source/css/_variables/base.styl","hash":"4ed5f0ae105ef4c7dd92eaf652ceda176c38e502","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_about/about.styl","hash":"97fe42516ea531fdad771489b68aa8b2a7f6ae46","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/color-schema.styl","hash":"61279540c2623ea4bf93e40613d41380839b92d3","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/base.styl","hash":"643284c567665f96915f0b64e59934dda315f74d","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/inline.styl","hash":"411a3fa3f924a87e00ff04d18b5c83283b049a4d","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/keyframes.styl","hash":"94065ea50f5bef7566d184f2422f6ac20866ba22","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_index/index.styl","hash":"0acbd71633bcc7191672ea4e1b2277bea350d73b","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_archive/archive.styl","hash":"c475e6681546d30350eaed11f23081ecae80c375","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_category/category-bar.styl","hash":"99e8e25e84d513b869a17140f63a5c1e48a0e7e1","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_category/category-chain.styl","hash":"0cdf7ef50dfd0669d3b257821384ff31cd81b7c9","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_category/category-list.styl","hash":"7edfe1b571ecca7d08f5f4dbcf76f4ffdcfbf0b5","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_links/links.styl","hash":"5c7f2044e3f1da05a3229537c06bd879836f8d6e","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_post/comment.styl","hash":"780f3788e7357bcd3f3262d781cb91bb53976a93","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_post/markdown.styl","hash":"1e3d3a82721e7c10bcfcecec6d81cf2979039452","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_post/highlight.styl","hash":"7054d79c9d5966fc57baf0adcdf3b19275987b62","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_post/post-tag.styl","hash":"27f70062415ccf66a9b6f4952db124fc1471fda5","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_post/post-page.styl","hash":"127bb5391370afe7fef2a297084d76406bc5e902","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_tag/tags.styl","hash":"65bfc01c76abc927fa1a23bf2422892b0d566c3f","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/anchorjs.styl","hash":"e0cebda4a6f499aff75e71417d88caa7ceb13b94","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/board.styl","hash":"4397037fc3f0033dbe546c33cd9dbdabd8cb1632","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/banner.styl","hash":"7a0bd629bc234fc75e3cc8e3715ffada92f09e73","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/code-widget.styl","hash":"b66ab013f0f37d724a149b85b3c7432afcf460ad","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footer.styl","hash":"2caaca71dd1ff63d583099ed817677dd267b457e","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"ae9289cc89649af2042907f8a003303b987f3404","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/copyright.styl","hash":"26f71a9cd60d96bb0cb5bbdf58150b8e524d9707","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/modal.styl","hash":"adf6c1e5c8e1fb41c77ce6e2258001df61245aa2","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/header.styl","hash":"896179810e1ee986208ae2d57a44719f6b839bde","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/ngrogress.styl","hash":"5d225357b4a58d46118e6616377168336ed44cb2","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/noscript.styl","hash":"0cf2f2bb44f456150d428016675d5876a9d2e2aa","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/pagination.styl","hash":"8bb1b68e5f3552cb48c2ffa31edbc53646a8fb4c","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"78704a94c0436097abfb0e0a57abeb3429c749b7","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/search.styl","hash":"10f7e91a91e681fb9fe46f9df7707b9ef78707c8","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"f0e429a27fa8a7658fcbddbb4d4dbe4afa12499a","modified":1655372397000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/toc.styl","hash":"9e7452aa2372153f25d7a4675c9d36d281a65d24","modified":1655372397000},{"_id":"themes/fluid/source/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1655372397000},{"_id":"themes/fluid/source/img/zaofan.png","hash":"c3f7a32a6d1f7e74dff1ef76f1975ac154e93bf2","modified":1657420867633},{"_id":"themes/fluid/source/img/ling.png","hash":"c677de1ed6151900b0cdfd0c7334283d02719c95","modified":1657422361714},{"_id":"themes/fluid/source/img/xiaomai.png","hash":"309d59b56be19fe9dcbc4da70b0fd120d0320f6e","modified":1657421761208},{"_id":"themes/fluid/source/img/avatar.png","hash":"38f1a758ee3e9b0c69dbacfcebe38e4a46cb29ef","modified":1657435221866},{"_id":"themes/fluid/source/img/huiye.png","hash":"f7b9d49dbdcb09e058beac377d300de5e398f92e","modified":1657420780740},{"_id":"themes/fluid/source/img/nvpu.png","hash":"26d82e924b043d15dd017ce926364a3d4be20f4d","modified":1657421952571},{"_id":"themes/fluid/source/img/saber.png","hash":"ee4ae905d5de800afe578b082fda14913e875118","modified":1657623761937},{"_id":"public/local-search.xml","hash":"20f05dfddd7c15a8b438ad0dfc1cf5340124c780","modified":1658220576453},{"_id":"public/about/index.html","hash":"45aaf18bf8ea99132e397847cb5dbf9a73d10818","modified":1657621820703},{"_id":"public/test/index.html","hash":"3105e6bbfccdf7bd10f59e7fa87116113c68a466","modified":1657621820703},{"_id":"public/2022/07/10/test/index.html","hash":"ca4fa60ab6a07dac613d9c7844958902423e965d","modified":1657457558183},{"_id":"public/2022/07/09/测试文章/index.html","hash":"366428ec3f9909991b81d74326d01886d27625f8","modified":1657457558183},{"_id":"public/2022/07/09/hello-world/index.html","hash":"5534a275c73c2d238c924c4016c5e73a48cfbf54","modified":1657457558183},{"_id":"public/tags/原创/index.html","hash":"ee4e8c7ddb48cd4d468dd4bc85e7867d57576a0a","modified":1657457558183},{"_id":"public/archives/index.html","hash":"7bcdb2c53ddff4a32d20776b7b21d885cae60637","modified":1658154785817},{"_id":"public/archives/2022/index.html","hash":"d5695e957d84520233b41fca2e905ba7c8b7134a","modified":1658154785817},{"_id":"public/archives/2022/07/index.html","hash":"387e76a11a25ae0cba9d903ac5d37222d355b774","modified":1658154785817},{"_id":"public/categories/测试/index.html","hash":"f5c22d1f50894f415eb336b4faf7c6b5b7a5e85b","modified":1657457558183},{"_id":"public/index.html","hash":"0d2c8b89eb79e82ece876780968cc673b6f068fb","modified":1658154785817},{"_id":"public/404.html","hash":"542ee758106b71c5f725d3f488ac5d5513740f70","modified":1657621820703},{"_id":"public/tags/index.html","hash":"2f95c7a47d21f57a820a9dfb3bfb75e2f66cdd9f","modified":1658154785817},{"_id":"public/categories/index.html","hash":"47a2821189ce98050fd75791ae3b0a623ea800f1","modified":1657680660106},{"_id":"public/links/index.html","hash":"b798c81eee10b543f7173541e6a4848845947a8f","modified":1657621820703},{"_id":"public/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1657441080216},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1657441080216},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1657441080216},{"_id":"public/img/smallsaber.png","hash":"352be575db4326bd34eace19a3bfb472f360ba5c","modified":1657441080216},{"_id":"public/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1657441080216},{"_id":"public/live2dw/assets/exp/f01.exp.json","hash":"84073a497ddb6e56c6cfc244a0fb217ba473abf9","modified":1657441080216},{"_id":"public/live2dw/assets/exp/f02.exp.json","hash":"241b6afafa2e25c6d7a54692a8b5aa060a137ab1","modified":1657441080216},{"_id":"public/live2dw/assets/exp/f03.exp.json","hash":"fbf7729e504f14f83f976827fcf62301a6579a34","modified":1657441080216},{"_id":"public/live2dw/assets/exp/f04.exp.json","hash":"35e746ede62e7090e7dfb08561d77772f58b4153","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/flickHead_00.mtn","hash":"f64c79c9171660db5c440bef229ac2e35a1597d5","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/flickHead_01.mtn","hash":"a1011d6bf397bcd3c3c968d9616f88fe1ffbc83c","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/idle_00.mtn","hash":"378b4577217c604c9d28ab4edf8b707c8d8c2fbb","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/flickHead_02.mtn","hash":"d3c9c0acb4dc25a2274f3b9faa71e5ce60ad92e4","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/idle_01.mtn","hash":"88c2494655dbb712b842f03232b619f381753d52","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/idle_02.mtn","hash":"7f5d2cf8706007c8659938eba132a68c470a4c26","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/pinchIn_02.mtn","hash":"aa0d66ca9b06c374577fd7e64e89756de1e1f2ae","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/pinchIn_01.mtn","hash":"a5fefb45115695db72b9499e627a51b2b9394f2c","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/pinchIn_00.mtn","hash":"70978b4c983f6a9fd6d3d9c24571586f7d6eac30","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/pinchOut_01.mtn","hash":"e05df948d08b17f34c993a9c1f901190509d5db0","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/pinchOut_00.mtn","hash":"e07fe8fd8c2810e3c1d28b730bd49c8c25849bad","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/pinchOut_02.mtn","hash":"b323fd350d334b33bbdfb31194ae664089986c27","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/shake_00.mtn","hash":"5185d02c7ab9f0bec3d4a890b54b2378e553373d","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/shake_01.mtn","hash":"e812985a56796e122018f9d57d1606a4866ff7d1","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/shake_02.mtn","hash":"2702970805e07777974c383613e631730982bcff","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/tapBody_01.mtn","hash":"78fca17436ab5e065e27f419f135aa6c0a0b52ef","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/tapBody_02.mtn","hash":"a75acb51c1191ce5050d3ee1af6f2dcc787c7c5e","modified":1657441080216},{"_id":"public/live2dw/assets/mtn/tapBody_00.mtn","hash":"835aa3d4a8fbd26c0bb66b164a19464fa3f17a99","modified":1657441080216},{"_id":"public/live2dw/assets/shizuku.model.json","hash":"19a05bd41b806a935cea42c2000626fc82da2536","modified":1657441080216},{"_id":"public/live2dw/assets/shizuku.physics.json","hash":"6484d646e79a44c83784c6ae434cf7349746c5c8","modified":1657441080216},{"_id":"public/live2dw/assets/shizuku.pose.json","hash":"ac5505efbf80ba0a2e5783d67fe232bc5c6f1f80","modified":1657441080216},{"_id":"public/live2dw/assets/snd/flickHead_00.mp3","hash":"356388d939006b03cf9e6158c603b58d4800bec1","modified":1657441080216},{"_id":"public/live2dw/assets/snd/flickHead_01.mp3","hash":"436d0bbccf6e7a2744447554947eee4563608970","modified":1657441080216},{"_id":"public/live2dw/assets/snd/flickHead_02.mp3","hash":"5f63477ce63f2073e24d68fea906fe136fe6349e","modified":1657441080216},{"_id":"public/live2dw/assets/snd/pinchIn_01.mp3","hash":"d5c8cc6f61b56222a83a5174f75006f83c3b88da","modified":1657441080216},{"_id":"public/live2dw/assets/snd/pinchIn_00.mp3","hash":"f9baa3b7cadec20b714135fc49cfab3ff6adeeb4","modified":1657441080216},{"_id":"public/live2dw/assets/snd/shake_00.mp3","hash":"f65dd58e7b44ec5c865d13c190316070b625b5fe","modified":1657441080216},{"_id":"public/live2dw/assets/snd/shake_01.mp3","hash":"c1e0e8a07ff268ee06c2b7825d1b645e193f21b9","modified":1657441080216},{"_id":"public/live2dw/assets/snd/tapBody_00.mp3","hash":"003e68a59a9c8392e230f34c91860efbd946277a","modified":1657441080216},{"_id":"public/live2dw/assets/snd/shake_02.mp3","hash":"8882b94bce00f09232588b7301badb105fa8acab","modified":1657441080216},{"_id":"public/live2dw/assets/snd/tapBody_02.mp3","hash":"15e7815ed0a0e5164e18e0c53b97aedc742a134d","modified":1657441080216},{"_id":"public/live2dw/assets/snd/tapBody_01.mp3","hash":"5314b50f153df71559e51e2586581c006df00722","modified":1657441080216},{"_id":"public/live2dw/lib/L2Dwidget.min.js","hash":"5f1a807437cc723bcadc3791d37add5ceed566a2","modified":1657441080216},{"_id":"public/live2dw/assets/moc/shizuku.1024/texture_00.png","hash":"21bdb28b31783e23b26b3aa061e90be4088665aa","modified":1657441080216},{"_id":"public/live2dw/assets/moc/shizuku.1024/texture_03.png","hash":"07f568a2bb8045b6bdff7783fb4daf62c821f9ab","modified":1657441080216},{"_id":"public/live2dw/assets/moc/shizuku.1024/texture_05.png","hash":"0cd00007fb8bff62a2eb08e1d7c43abab8722224","modified":1657441080216},{"_id":"public/live2dw/assets/snd/pinchOut_01.mp3","hash":"8a081030fd53c07bffe3edd48f87a371ca77296b","modified":1657441080216},{"_id":"public/live2dw/assets/snd/pinchOut_00.mp3","hash":"0654f38f6e9fd623eaf8be11b5d58c9d12991949","modified":1657441080216},{"_id":"public/live2dw/assets/snd/pinchIn_02.mp3","hash":"5b63e02607571ac601c500995e836e6c861b1c62","modified":1657441080216},{"_id":"public/live2dw/assets/snd/pinchOut_02.mp3","hash":"554edb2f3838cbdc27d1a9c6b8a9cb6eb465cbdd","modified":1657441080216},{"_id":"public/live2dw/lib/L2Dwidget.min.js.map","hash":"3290fe2df45f065b51a1cd7b24ec325cbf9bb5ce","modified":1657441080216},{"_id":"public/css/gitalk.css","hash":"2234d7496740d11b5b53aaaef9155dcb2c6f3f73","modified":1657441080216},{"_id":"public/css/highlight-dark.css","hash":"5ab9082a6fd29f7f8ffad02a606967bb841a2ab4","modified":1657441080216},{"_id":"public/css/highlight.css","hash":"54b718c687ce8460e10d501c1eb53a8098942c1e","modified":1657441080216},{"_id":"public/js/background.js","hash":"78e8eadcb8e9053878220e6c68607cd5e80f3b59","modified":1657441080216},{"_id":"public/js/boot.js","hash":"2848f8eb5081a7f0550fbd76dc06d3ff877f1913","modified":1657441080216},{"_id":"public/js/firework.js","hash":"dacd158ae8b7e67bb0b7323b6c2595efe72f29f7","modified":1657441080216},{"_id":"public/js/events.js","hash":"f05a569a9fd6da2fda69a2cf8e276ba81580faf3","modified":1657441080216},{"_id":"public/js/color-schema.js","hash":"ba63f7c3324bc1fdd050a90add9d8faaffc27e07","modified":1657441080216},{"_id":"public/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1657441080216},{"_id":"public/js/local-search.js","hash":"cebcda5991b6a9ab9307c69542389ce9013f04f7","modified":1657441080216},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1657441080216},{"_id":"public/js/utils.js","hash":"45cc86f099db0a2c36ad49711ce66c2d598a2ab1","modified":1657441080216},{"_id":"public/js/plugins.js","hash":"2333494add51e5e1374602a4e81f0be36a05d4c2","modified":1657441080216},{"_id":"public/css/main.css","hash":"f80a13b2e8049bedef90f8e46d2748b023203046","modified":1657441080216},{"_id":"public/live2dw/assets/moc/shizuku.1024/texture_01.png","hash":"3d0e745f3e560071ee08beeecde186e5ea35d99e","modified":1657441080216},{"_id":"public/live2dw/assets/moc/shizuku.1024/texture_04.png","hash":"f764d594841905db8b2998dd61c329866125ad97","modified":1657441080216},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js","hash":"35bb5b588b6de25c9be2dd51d3fd331feafac02d","modified":1657441080216},{"_id":"public/live2dw/assets/moc/shizuku.1024/texture_02.png","hash":"055eb2da9c13e9116be93a1e60c0ea2b660af864","modified":1657441080216},{"_id":"public/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1657441080216},{"_id":"public/img/zaofan.png","hash":"c3f7a32a6d1f7e74dff1ef76f1975ac154e93bf2","modified":1657441080216},{"_id":"public/img/ling.png","hash":"c677de1ed6151900b0cdfd0c7334283d02719c95","modified":1657441080216},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js.map","hash":"35e71cc2a130199efb167b9a06939576602f0d75","modified":1657441080216},{"_id":"public/live2dw/assets/moc/shizuku.moc","hash":"c2670a0f75830edc89d7fe6d074de4ee67e8dc5d","modified":1657441080216},{"_id":"public/img/xiaomai.png","hash":"309d59b56be19fe9dcbc4da70b0fd120d0320f6e","modified":1657441080216},{"_id":"public/img/avatar.png","hash":"38f1a758ee3e9b0c69dbacfcebe38e4a46cb29ef","modified":1657441080216},{"_id":"public/img/huiye.png","hash":"f7b9d49dbdcb09e058beac377d300de5e398f92e","modified":1657441080216},{"_id":"public/img/nvpu.png","hash":"26d82e924b043d15dd017ce926364a3d4be20f4d","modified":1657441080216},{"_id":"public/img/saber.png","hash":"ba2384da2740242861a1e40b4d5a71da1c0bda09","modified":1657441080216},{"_id":"themes/fluid/source/img/zaofan.jpg","hash":"0613102b35ab355348657fefd973c4447aaff29d","modified":1657454908184},{"_id":"public/img/zaofan.jpg","hash":"0613102b35ab355348657fefd973c4447aaff29d","modified":1657455353415},{"_id":"source/_drafts/test.md","hash":"6923be2719c6a38afac094ed42e25288285b60ac","modified":1657466619265},{"_id":"source/_discarded/test.md","hash":"6923be2719c6a38afac094ed42e25288285b60ac","modified":1657466626940},{"_id":"source/_discarded/测试文章.md","hash":"06cf24f863e374f2e29161859bcbc5fae0f349f0","modified":1657466637476},{"_id":"source/_drafts/hello-world.md","hash":"f602f8fd96eb4963458ecc9c25123b87377b3c40","modified":1657466658505},{"_id":"source/_discarded/hello-world.md","hash":"f602f8fd96eb4963458ecc9c25123b87377b3c40","modified":1657466660525},{"_id":"source/_drafts/博客迁移公告.md","hash":"531db1d8a8d72cc7a75ffdb488121425e2280cde","modified":1657466813536},{"_id":"source/_drafts/CMU149-lab0-环境搭建.md","hash":"55519f3c40a6ee6ccdb81377c458ed14b5c3da17","modified":1657467573703},{"_id":"source/_posts/博客迁移公告.md","hash":"531db1d8a8d72cc7a75ffdb488121425e2280cde","modified":1657466817029},{"_id":"source/_drafts/lab1-Parallel-Fractal-Generation-Using-Threads.md","hash":"88fc4b4c9d78f29be1ec3b04c830ec4cd09c66d2","modified":1657468457741},{"_id":"source/_posts/CMU149-lab0-环境搭建.md","hash":"b7b9e1c8d11655bce9b87d2e392770cf890a277e","modified":1657468505371},{"_id":"source/_posts/lab1-Parallel-Fractal-Generation-Using-Threads.md","hash":"88fc4b4c9d78f29be1ec3b04c830ec4cd09c66d2","modified":1657468459046},{"_id":"public/2022/07/10/lab1-Parallel-Fractal-Generation-Using-Threads/index.html","hash":"0c5f24c79eb3bf1ec98ba3a3cae8081a4145d7f4","modified":1657621820703},{"_id":"public/2022/07/10/博客迁移公告/index.html","hash":"a6b5bccab7506c28ece26e098ee1d01664bb40e4","modified":1657621820703},{"_id":"public/categories/课程学习/index.html","hash":"ff47a3d6d375fbb69d28811c84a03af7a9a962a4","modified":1657621820703},{"_id":"public/tags/CMU-149/index.html","hash":"ba662d75fbd21ef2486571e090fbb98eafbb28d5","modified":1657621820703},{"_id":"public/2022/07/10/CMU149-lab0-环境搭建/index.html","hash":"4fd6ba7a453e8f18998eb90c1da8fa63a4c45e08","modified":1657621820703},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记.md","hash":"2876d6895bfaded03a87843265a949dbbacb665b","modified":1658139745419},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/Encoder.jpg","hash":"ed24fb35effd00bc5af4ea4c6a2c42d49d961cc1","modified":1657518773157},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/lbtuidao.png","hash":"8794435d6212d3ecae5058d7919fa0d92c223454","modified":1657543026180},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/Lb.png","hash":"1ed3fcb6ef3e295f1bcc13246d64e297ffc765a2","modified":1657530097073},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/model.jpg","hash":"22daf29ba9687b2c0358af792f68da612fc1b6b9","modified":1657519028686},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/maximum.png","hash":"e0f463022c035fb9ecfaf572c080bd74c957bf30","modified":1657529715635},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/trans.png","hash":"9be5a8a716cd07dc7b33ebe2ac28c229ab8350f6","modified":1657529852197},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/yuanshi.png","hash":"cf8588ea5ffd200e6a606e8396272b536a673b96","modified":1657530107968},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/Decoder.jpg","hash":"e37e4e74e6d775ff946a743d0255108e80f1c814","modified":1657543457495},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/noise.jpg","hash":"4cd0a301ca315ac07d5038a674c2afe14e6e1401","modified":1657529265309},{"_id":"public/2022/07/11/VAE-Auto-Encoding-Variational-Bayes-学习笔记/index.html","hash":"de45a9c84aa4a0e2004c0322905b810c94baf353","modified":1658154785817},{"_id":"public/categories/实验室/index.html","hash":"6e84b2dd8a624262719337b6714787cb77626a1e","modified":1657680660106},{"_id":"public/tags/VAE/index.html","hash":"878eed6811843da2dafe764f8f8a44e3161ef95e","modified":1658154785817},{"_id":"public/tags/深度学习/index.html","hash":"c05f118a83f2d806e85708a308135e46840556e0","modified":1658154785817},{"_id":"public/tags/笔记/index.html","hash":"50a49cc314d64deafbe6eeff3406788225f5c9ce","modified":1657621820703},{"_id":"public/2022/07/11/VAE-Auto-Encoding-Variational-Bayes-学习笔记/Decoder.jpg","hash":"e37e4e74e6d775ff946a743d0255108e80f1c814","modified":1657621675936},{"_id":"public/2022/07/11/VAE-Auto-Encoding-Variational-Bayes-学习笔记/Encoder.jpg","hash":"ed24fb35effd00bc5af4ea4c6a2c42d49d961cc1","modified":1657621675936},{"_id":"public/2022/07/11/VAE-Auto-Encoding-Variational-Bayes-学习笔记/Lb.png","hash":"1ed3fcb6ef3e295f1bcc13246d64e297ffc765a2","modified":1657621675936},{"_id":"public/2022/07/11/VAE-Auto-Encoding-Variational-Bayes-学习笔记/lbtuidao.png","hash":"8794435d6212d3ecae5058d7919fa0d92c223454","modified":1657621675936},{"_id":"public/2022/07/11/VAE-Auto-Encoding-Variational-Bayes-学习笔记/maximum.png","hash":"e0f463022c035fb9ecfaf572c080bd74c957bf30","modified":1657621675936},{"_id":"public/2022/07/11/VAE-Auto-Encoding-Variational-Bayes-学习笔记/model.jpg","hash":"22daf29ba9687b2c0358af792f68da612fc1b6b9","modified":1657621675936},{"_id":"public/2022/07/11/VAE-Auto-Encoding-Variational-Bayes-学习笔记/trans.png","hash":"9be5a8a716cd07dc7b33ebe2ac28c229ab8350f6","modified":1657621675936},{"_id":"public/2022/07/11/VAE-Auto-Encoding-Variational-Bayes-学习笔记/noise.jpg","hash":"4cd0a301ca315ac07d5038a674c2afe14e6e1401","modified":1657621675936},{"_id":"public/2022/07/11/VAE-Auto-Encoding-Variational-Bayes-学习笔记/yuanshi.png","hash":"cf8588ea5ffd200e6a606e8396272b536a673b96","modified":1657621675936},{"_id":"source/_posts/使用yfinance获取美股数据的时报错.md","hash":"ffa327732317cb704ac242a1b2a3d4c647ea3174","modified":1657680611123},{"_id":"public/tags/智能投顾/index.html","hash":"66cfd5c9caa19e87ce2c481514db241dd9fe816e","modified":1657680660106},{"_id":"public/2022/07/13/使用yfinance获取美股数据的时报错/index.html","hash":"9598f5d6f8a1e04bdfc9142c9f6c6659953b9c76","modified":1658154785817},{"_id":"source/_drafts/Generative-Adversarial-Network-GAN-学习笔记.md","hash":"2bcdd8863f5f5d47565ea9e77916100799511ccc","modified":1658139643269},{"_id":"source/_posts/Generative-Adversarial-Network-GAN-学习笔记.md","hash":"3c9ee606a48934381b72f0f0f0bbbbe25c5a23f2","modified":1658220640980},{"_id":"source/_posts/Generative Adversarial Network(GAN)/bianbieqi.png","hash":"2ec9662f837bed65dbb12918fbfea0cc98bc4695","modified":1658124332000},{"_id":"source/_posts/Generative Adversarial Network(GAN)/fenbuxiangjiao.png","hash":"9af435068729d003cc947eebe8df07452cdeb90c","modified":1658124332000},{"_id":"source/_posts/Generative Adversarial Network(GAN)/jsproblem.png","hash":"014438923e032285d4720d403f4cd80418ed3a88","modified":1658124332000},{"_id":"source/_posts/Generative Adversarial Network(GAN)/sample.png","hash":"9408e857f67fe0c67d093891ac98356cdf9a5122","modified":1658124332000},{"_id":"source/_posts/Generative Adversarial Network(GAN)/shoulian.png","hash":"d2cb4b11109599e491ce4c17aa4fe7c96461f4a9","modified":1658124332000},{"_id":"source/_posts/Generative Adversarial Network(GAN)/theoryimage.png","hash":"74196311eeb057076276d0e1b0b438c6cc8bbfde","modified":1658124332000},{"_id":"source/_posts/Generative Adversarial Network(GAN)/theoryshizi.png","hash":"8404445937e996420842f3ed15dbc6d0a49490d5","modified":1658124332000},{"_id":"source/_posts/Generative Adversarial Network(GAN)/wdistance.png","hash":"03ec3052c15c6b6d91e50e658a3dfc7e9cd977f5","modified":1658124332000},{"_id":"source/_posts/Generative Adversarial Network(GAN)/wshizi.png","hash":"0a4530239eb3d724a8335ac93702ea325eef17ec","modified":1658124332000},{"_id":"source/_posts/Generative Adversarial Network(GAN)/zhiguanbianbie.png","hash":"7550218fce866a29df9ac5662293bbbac968a305","modified":1658124334000},{"_id":"source/_posts/Generative Adversarial Network(GAN)/zuixiaohua.png","hash":"206c1cae513969654b7e34eb91f58d0050408834","modified":1658124334000},{"_id":"source/_posts/Generative Adversarial Network(GAN)/zhiguanlijie.png","hash":"3b02ae646e98ed66ef0728086f0d9319dd857a06","modified":1658124334000},{"_id":"source/_posts/Generative Adversarial Network(GAN)/algorithm1.png","hash":"a81e5b5df3282ffe9f1f08daf4f0a8b74d5ca27b","modified":1658153356883},{"_id":"public/2022/07/18/Generative-Adversarial-Network-GAN-学习笔记/index.html","hash":"cd77283bf5146b304d5c24be5d9895e10d10a1d4","modified":1658220576453},{"_id":"public/tags/GAN/index.html","hash":"1464411d27ade6eb41884cb151967dd966bdc933","modified":1658154785817},{"_id":"source/_posts/Generative Adversarial Network(GAN)/Lip.png","hash":"afbcf07254273041ce07675eed3b6b22e2917ad7","modified":1658217676226},{"_id":"source/_posts/Generative Adversarial Network(GAN)/gp.png","hash":"ab75bda613c7845e767accf18fbb929416dae619","modified":1658217975272},{"_id":"source/_posts/Generative Adversarial Network(GAN)/jifen.png","hash":"3f20b89143ec2ec333f328a1b866ca0ec5202c82","modified":1658218799292},{"_id":"source/_posts/Generative Adversarial Network(GAN)/ppen.png","hash":"9afb8034735fa3c94b9a037c2582e62608c9dbe9","modified":1658219202382},{"_id":"source/_posts/Generative Adversarial Network(GAN)/jifen1.png","hash":"e253f77944c79da2e60c7406c94ad4a9f8236705","modified":1658219525999},{"_id":"source/_posts/Generative Adversarial Network(GAN)/improve.png","hash":"fd66c5c14b9be8fe894003ea92e62b4a45ea19b8","modified":1658219983893},{"_id":"source/_posts/Generative Adversarial Network(GAN)/wgan.png","hash":"4b97ca57b54a1cf97c545fdc1e1afc0335d43078","modified":1658220531563},{"_id":"source/_drafts/VAE-GAN-结合-论文梳理.md","hash":"0596b6c635468bc2a7cab363b81eb4330a588d92","modified":1658220717455}],"Category":[{"name":"测试","_id":"cl5f1mjjb0004eoyzfo03ewum"},{"name":"课程学习","_id":"cl5fh8nlc0003moyz0wd77czi"},{"name":"实验室","_id":"cl5i15m7x0001n0yzh3ue7pzu"}],"Data":[],"Page":[{"title":"about","date":"2022-07-09T03:53:47.000Z","layout":"about","_content":"\n这里是大财主的代码乐园啦","source":"about/index.md","raw":"---\ntitle: about\ndate: 2022-07-09 11:53:47\nlayout: about\n---\n\n这里是大财主的代码乐园啦","updated":"2022-07-09T15:18:06.141Z","path":"about/index.html","comments":1,"_id":"cl5f1mjiy0000eoyzcry71pol","content":"<p>这里是大财主的代码乐园啦</p>\n","site":{"data":{}},"wordcount":12,"excerpt":"","more":"<p>这里是大财主的代码乐园啦</p>\n"},{"title":"test","date":"2022-07-10T03:07:01.000Z","_content":"","source":"test/index.md","raw":"---\ntitle: test\ndate: 2022-07-10 11:07:01\n---\n","updated":"2022-07-10T03:07:01.585Z","path":"test/index.html","comments":1,"layout":"page","_id":"cl5f1mjj50002eoyz2rtcaesq","content":"","site":{"data":{}},"wordcount":0,"excerpt":"","more":""}],"Post":[{"title":"Hello World","date":"2022-07-09T03:05:00.000Z","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_discarded//hello-world.md","raw":"title: Hello World\ntags: []\ncategories: []\ndate: 2022-07-09 11:05:00\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":0,"updated":"2022-07-10T15:24:20.519Z","_id":"cl5f1mjj10001eoyzfb5qayit","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo new <span class=\"hljs-string\">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo server<br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo generate<br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo deploy<br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","site":{"data":{}},"wordcount":367,"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo new <span class=\"hljs-string\">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo server<br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo generate<br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo deploy<br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"测试文章","date":"2022-07-09T15:19:59.000Z","_content":"\n这是一篇测试文章\n","source":"_discarded//测试文章.md","raw":"title: 测试文章\ntags:\n  - 原创\ncategories:\n  - 测试\ndate: 2022-07-09 23:19:59\n---\n\n这是一篇测试文章\n","slug":"测试文章","published":0,"updated":"2022-07-10T15:23:57.474Z","_id":"cl5f1mjj60003eoyzb4wad629","comments":1,"layout":"post","photos":[],"link":"","content":"<p>这是一篇测试文章</p>\n","site":{"data":{}},"wordcount":8,"excerpt":"","more":"<p>这是一篇测试文章</p>\n"},{"title":"test","date":"2022-07-10T03:08:00.000Z","_content":"\n测试","source":"_discarded//test.md","raw":"title: test\ntags: []\ncategories: []\ndate: 2022-07-10 11:08:00\n---\n\n测试","slug":"test","published":0,"updated":"2022-07-10T15:23:46.934Z","_id":"cl5f1mjjf0008eoyz7vs6eo4p","comments":1,"layout":"post","photos":[],"link":"","content":"<p>测试</p>\n","site":{"data":{}},"wordcount":2,"excerpt":"","more":"<p>测试</p>\n"},{"title":"博客迁移公告","author":"boss","date":"2022-07-10T15:24:55.000Z","_content":"Hello 大家好, 欢迎来到大财主的代码乐园\n\n之前的博客记录可以访问\n\n<https://www.cnblogs.com/wuenze/>\n\n","source":"_posts/博客迁移公告.md","raw":"title: 博客迁移公告\nauthor: boss\ndate: 2022-07-10 23:24:55\ntags:\n---\nHello 大家好, 欢迎来到大财主的代码乐园\n\n之前的博客记录可以访问\n\n<https://www.cnblogs.com/wuenze/>\n\n","slug":"博客迁移公告","published":1,"updated":"2022-07-10T15:26:57.029Z","_id":"cl5fgvcfj0000moyzf4y21keq","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Hello 大家好, 欢迎来到大财主的代码乐园</p>\n<p>之前的博客记录可以访问</p>\n<p><a href=\"https://www.cnblogs.com/wuenze/\">https://www.cnblogs.com/wuenze/</a></p>\n","site":{"data":{}},"wordcount":63,"excerpt":"","more":"<p>Hello 大家好, 欢迎来到大财主的代码乐园</p>\n<p>之前的博客记录可以访问</p>\n<p><a href=\"https://www.cnblogs.com/wuenze/\">https://www.cnblogs.com/wuenze/</a></p>\n"},{"title":"CMU149 lab0 环境搭建","author":"boss","date":"2022-07-10T15:33:00.000Z","_content":"\n# 环境搭建\n\n附上官方地址:\n\n<https://github.com/stanford-cs149/asst1>\n\n## 安装 ISPC\n\n首先需要安装 ISPC\n\n我这里是 win11 使用 wsl 虚拟机 \n如果虚拟机或者 linux 系统一样的操作\n\n\n`wget https://github.com/ispc/ispc/releases/download/v1.16.1/ispc-v1.16.1-linux.tar.gz`\n\n下载后解压\n\n`tar -xvf ispc-v1.16.1-linux.tar.gz`\n\n## 添加环境变量\n\n`export PATH=$PATH:${HOME}/ispc-v1.16.1-linux/bin`\n\n如果只在命令行里输入的话是临时的，下次就没有了\n所以我们最好添加永久的环境变量\n\nbash 用户可以添加到 ~/.bashrc 文件中\n\n\n我这里在 zsh 添加了永久的环境变量\n\n添加后输入\n\n`source $HOME/.zshrc`\n\n使环境变量生效\n\n如果 lab1 的样例程序编译通过就代表安装成功了\n\n[lab1 Parallel Fractal Generation Using Threads](http://bossalex.top/2022/07/10/lab1-Parallel-Fractal-Generation-Using-Threads/)","source":"_posts/CMU149-lab0-环境搭建.md","raw":"title: CMU149 lab0 环境搭建\nauthor: boss\ntags:\n  - CMU 149\ncategories:\n  - 课程学习\ndate: 2022-07-10 23:33:00\n---\n\n# 环境搭建\n\n附上官方地址:\n\n<https://github.com/stanford-cs149/asst1>\n\n## 安装 ISPC\n\n首先需要安装 ISPC\n\n我这里是 win11 使用 wsl 虚拟机 \n如果虚拟机或者 linux 系统一样的操作\n\n\n`wget https://github.com/ispc/ispc/releases/download/v1.16.1/ispc-v1.16.1-linux.tar.gz`\n\n下载后解压\n\n`tar -xvf ispc-v1.16.1-linux.tar.gz`\n\n## 添加环境变量\n\n`export PATH=$PATH:${HOME}/ispc-v1.16.1-linux/bin`\n\n如果只在命令行里输入的话是临时的，下次就没有了\n所以我们最好添加永久的环境变量\n\nbash 用户可以添加到 ~/.bashrc 文件中\n\n\n我这里在 zsh 添加了永久的环境变量\n\n添加后输入\n\n`source $HOME/.zshrc`\n\n使环境变量生效\n\n如果 lab1 的样例程序编译通过就代表安装成功了\n\n[lab1 Parallel Fractal Generation Using Threads](http://bossalex.top/2022/07/10/lab1-Parallel-Fractal-Generation-Using-Threads/)","slug":"CMU149-lab0-环境搭建","published":1,"updated":"2022-07-10T15:55:05.371Z","_id":"cl5fh6o970001moyzbvhnc8ff","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"环境搭建\"><a href=\"#环境搭建\" class=\"headerlink\" title=\"环境搭建\"></a>环境搭建</h1><p>附上官方地址:</p>\n<p><a href=\"https://github.com/stanford-cs149/asst1\">https://github.com/stanford-cs149/asst1</a></p>\n<h2 id=\"安装-ISPC\"><a href=\"#安装-ISPC\" class=\"headerlink\" title=\"安装 ISPC\"></a>安装 ISPC</h2><p>首先需要安装 ISPC</p>\n<p>我这里是 win11 使用 wsl 虚拟机<br>如果虚拟机或者 linux 系统一样的操作</p>\n<p><code>wget https://github.com/ispc/ispc/releases/download/v1.16.1/ispc-v1.16.1-linux.tar.gz</code></p>\n<p>下载后解压</p>\n<p><code>tar -xvf ispc-v1.16.1-linux.tar.gz</code></p>\n<h2 id=\"添加环境变量\"><a href=\"#添加环境变量\" class=\"headerlink\" title=\"添加环境变量\"></a>添加环境变量</h2><p><code>export PATH=$PATH:$&#123;HOME&#125;/ispc-v1.16.1-linux/bin</code></p>\n<p>如果只在命令行里输入的话是临时的，下次就没有了<br>所以我们最好添加永久的环境变量</p>\n<p>bash 用户可以添加到 ~/.bashrc 文件中</p>\n<p>我这里在 zsh 添加了永久的环境变量</p>\n<p>添加后输入</p>\n<p><code>source $HOME/.zshrc</code></p>\n<p>使环境变量生效</p>\n<p>如果 lab1 的样例程序编译通过就代表安装成功了</p>\n<p><a href=\"http://bossalex.top/2022/07/10/lab1-Parallel-Fractal-Generation-Using-Threads/\">lab1 Parallel Fractal Generation Using Threads</a></p>\n","site":{"data":{}},"wordcount":458,"excerpt":"","more":"<h1 id=\"环境搭建\"><a href=\"#环境搭建\" class=\"headerlink\" title=\"环境搭建\"></a>环境搭建</h1><p>附上官方地址:</p>\n<p><a href=\"https://github.com/stanford-cs149/asst1\">https://github.com/stanford-cs149/asst1</a></p>\n<h2 id=\"安装-ISPC\"><a href=\"#安装-ISPC\" class=\"headerlink\" title=\"安装 ISPC\"></a>安装 ISPC</h2><p>首先需要安装 ISPC</p>\n<p>我这里是 win11 使用 wsl 虚拟机<br>如果虚拟机或者 linux 系统一样的操作</p>\n<p><code>wget https://github.com/ispc/ispc/releases/download/v1.16.1/ispc-v1.16.1-linux.tar.gz</code></p>\n<p>下载后解压</p>\n<p><code>tar -xvf ispc-v1.16.1-linux.tar.gz</code></p>\n<h2 id=\"添加环境变量\"><a href=\"#添加环境变量\" class=\"headerlink\" title=\"添加环境变量\"></a>添加环境变量</h2><p><code>export PATH=$PATH:$&#123;HOME&#125;/ispc-v1.16.1-linux/bin</code></p>\n<p>如果只在命令行里输入的话是临时的，下次就没有了<br>所以我们最好添加永久的环境变量</p>\n<p>bash 用户可以添加到 ~/.bashrc 文件中</p>\n<p>我这里在 zsh 添加了永久的环境变量</p>\n<p>添加后输入</p>\n<p><code>source $HOME/.zshrc</code></p>\n<p>使环境变量生效</p>\n<p>如果 lab1 的样例程序编译通过就代表安装成功了</p>\n<p><a href=\"http://bossalex.top/2022/07/10/lab1-Parallel-Fractal-Generation-Using-Threads/\">lab1 Parallel Fractal Generation Using Threads</a></p>\n"},{"title":"CMU 149 lab1 Parallel Fractal Generation Using Threads","author":"boss","date":"2022-07-10T15:54:15.000Z","_content":"","source":"_posts/lab1-Parallel-Fractal-Generation-Using-Threads.md","raw":"title: CMU 149 lab1 Parallel Fractal Generation Using Threads\nauthor: boss\ndate: 2022-07-10 23:54:15\ntags:\n---\n","slug":"lab1-Parallel-Fractal-Generation-Using-Threads","published":1,"updated":"2022-07-10T15:54:19.046Z","_id":"cl5fhx3bi0006moyzbuw3efhm","comments":1,"layout":"post","photos":[],"link":"","content":"","site":{"data":{}},"wordcount":0,"excerpt":"","more":""},{"title":"VAE Auto-Encoding Variational Bayes 学习笔记","author":"boss","date":"2022-07-11T05:35:00.000Z","_content":"\n# VAE 学习笔记\n\n李宏毅老师的 [课程视频](https://www.bilibili.com/video/av15889450/?p=33) 讲的很详细，记录一下\n\n## 直观理解\n\nVAE 的大体结构和 Auto-Encoder 类似\n区别在于 VAE 在生成的过程中加入了噪音, 使模型具有了生成能力\n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/noise.jpg\"></div>\n\n\n## VAE 的构造\n从下图的结构可以看出，VAE 的 Encoder 会求出一个隐藏层的分布，然后对这个分布进行采样，生成一个 X', 理想的情况下，这个 X' 和 X 的距离应该是很小的\n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/model.jpg\"></div>\n\n但是问题在于，如果我们优化函数只优化最终结果的距离，那么X'最准确的情况的下分布的方差会变为 0, 此时的 VAE 事实上就退化成了 auto-encoder。 因此我们需要在 Loss 中加入对分布的限制, 从而达到较好的生成效果。\n\n## 公式推导\n\n我们的目标是求解\n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/maximum.png\"></div>\n\n\n这个式子可以进行变换:\n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/trans.png\"></div>\n\n于是我们得到了一个 logP(x)的下界:\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Lb.png\"></div>\n\n此时原式化为: \n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/yuanshi.png\"></div>\n\n这里要补充一点，当我们在优化 Lb 的时候, KL散度是像0趋近的，这样我们logP(x)就会接近优化的下界。\n\n注意到 \n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/lbtuidao.png\"></div>\n\n\n因此只需要构造两个求解器，分别是 Encoder 和 Decoder\n\n其中 Encoder 求解的是 q(z|x) 的分布，我们希望所有的 q(z|x) 都能近似 p(z) 的分布。z 的分布在 VAE 中定义成 N(0, 1)\n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Encoder.jpg\"></div>\n\nDecoder 求解的是 p(x|z) 的分布\n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Decoder.jpg\"></div>\n\n\n至此证明完毕\n\n\n\n\n","source":"_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记.md","raw":"title: VAE Auto-Encoding Variational Bayes 学习笔记\nauthor: boss\ntags:\n  - VAE\n  - 深度学习\n  - 笔记\ncategories:\n  - 实验室\ndate: 2022-07-11 13:35:00\n---\n\n# VAE 学习笔记\n\n李宏毅老师的 [课程视频](https://www.bilibili.com/video/av15889450/?p=33) 讲的很详细，记录一下\n\n## 直观理解\n\nVAE 的大体结构和 Auto-Encoder 类似\n区别在于 VAE 在生成的过程中加入了噪音, 使模型具有了生成能力\n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/noise.jpg\"></div>\n\n\n## VAE 的构造\n从下图的结构可以看出，VAE 的 Encoder 会求出一个隐藏层的分布，然后对这个分布进行采样，生成一个 X', 理想的情况下，这个 X' 和 X 的距离应该是很小的\n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/model.jpg\"></div>\n\n但是问题在于，如果我们优化函数只优化最终结果的距离，那么X'最准确的情况的下分布的方差会变为 0, 此时的 VAE 事实上就退化成了 auto-encoder。 因此我们需要在 Loss 中加入对分布的限制, 从而达到较好的生成效果。\n\n## 公式推导\n\n我们的目标是求解\n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/maximum.png\"></div>\n\n\n这个式子可以进行变换:\n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/trans.png\"></div>\n\n于是我们得到了一个 logP(x)的下界:\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Lb.png\"></div>\n\n此时原式化为: \n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/yuanshi.png\"></div>\n\n这里要补充一点，当我们在优化 Lb 的时候, KL散度是像0趋近的，这样我们logP(x)就会接近优化的下界。\n\n注意到 \n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/lbtuidao.png\"></div>\n\n\n因此只需要构造两个求解器，分别是 Encoder 和 Decoder\n\n其中 Encoder 求解的是 q(z|x) 的分布，我们希望所有的 q(z|x) 都能近似 p(z) 的分布。z 的分布在 VAE 中定义成 N(0, 1)\n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Encoder.jpg\"></div>\n\nDecoder 求解的是 p(x|z) 的分布\n\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Decoder.jpg\"></div>\n\n\n至此证明完毕\n\n\n\n\n","slug":"VAE-Auto-Encoding-Variational-Bayes-学习笔记","published":1,"updated":"2022-07-18T10:22:25.419Z","_id":"cl5i15m700000n0yz51h5hjz5","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"VAE-学习笔记\"><a href=\"#VAE-学习笔记\" class=\"headerlink\" title=\"VAE 学习笔记\"></a>VAE 学习笔记</h1><p>李宏毅老师的 <a href=\"https://www.bilibili.com/video/av15889450/?p=33\">课程视频</a> 讲的很详细，记录一下</p>\n<h2 id=\"直观理解\"><a href=\"#直观理解\" class=\"headerlink\" title=\"直观理解\"></a>直观理解</h2><p>VAE 的大体结构和 Auto-Encoder 类似<br>区别在于 VAE 在生成的过程中加入了噪音, 使模型具有了生成能力</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/noise.jpg\"></div>\n\n\n<h2 id=\"VAE-的构造\"><a href=\"#VAE-的构造\" class=\"headerlink\" title=\"VAE 的构造\"></a>VAE 的构造</h2><p>从下图的结构可以看出，VAE 的 Encoder 会求出一个隐藏层的分布，然后对这个分布进行采样，生成一个 X’, 理想的情况下，这个 X’ 和 X 的距离应该是很小的</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/model.jpg\"></div>\n\n<p>但是问题在于，如果我们优化函数只优化最终结果的距离，那么X’最准确的情况的下分布的方差会变为 0, 此时的 VAE 事实上就退化成了 auto-encoder。 因此我们需要在 Loss 中加入对分布的限制, 从而达到较好的生成效果。</p>\n<h2 id=\"公式推导\"><a href=\"#公式推导\" class=\"headerlink\" title=\"公式推导\"></a>公式推导</h2><p>我们的目标是求解</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/maximum.png\"></div>\n\n\n<p>这个式子可以进行变换:</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/trans.png\"></div>\n\n<p>于是我们得到了一个 logP(x)的下界:</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Lb.png\"></div>\n\n<p>此时原式化为: </p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/yuanshi.png\"></div>\n\n<p>这里要补充一点，当我们在优化 Lb 的时候, KL散度是像0趋近的，这样我们logP(x)就会接近优化的下界。</p>\n<p>注意到 </p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/lbtuidao.png\"></div>\n\n\n<p>因此只需要构造两个求解器，分别是 Encoder 和 Decoder</p>\n<p>其中 Encoder 求解的是 q(z|x) 的分布，我们希望所有的 q(z|x) 都能近似 p(z) 的分布。z 的分布在 VAE 中定义成 N(0, 1)</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Encoder.jpg\"></div>\n\n<p>Decoder 求解的是 p(x|z) 的分布</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Decoder.jpg\"></div>\n\n\n<p>至此证明完毕</p>\n","site":{"data":{}},"wordcount":501,"excerpt":"","more":"<h1 id=\"VAE-学习笔记\"><a href=\"#VAE-学习笔记\" class=\"headerlink\" title=\"VAE 学习笔记\"></a>VAE 学习笔记</h1><p>李宏毅老师的 <a href=\"https://www.bilibili.com/video/av15889450/?p=33\">课程视频</a> 讲的很详细，记录一下</p>\n<h2 id=\"直观理解\"><a href=\"#直观理解\" class=\"headerlink\" title=\"直观理解\"></a>直观理解</h2><p>VAE 的大体结构和 Auto-Encoder 类似<br>区别在于 VAE 在生成的过程中加入了噪音, 使模型具有了生成能力</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/noise.jpg\"></div>\n\n\n<h2 id=\"VAE-的构造\"><a href=\"#VAE-的构造\" class=\"headerlink\" title=\"VAE 的构造\"></a>VAE 的构造</h2><p>从下图的结构可以看出，VAE 的 Encoder 会求出一个隐藏层的分布，然后对这个分布进行采样，生成一个 X’, 理想的情况下，这个 X’ 和 X 的距离应该是很小的</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/model.jpg\"></div>\n\n<p>但是问题在于，如果我们优化函数只优化最终结果的距离，那么X’最准确的情况的下分布的方差会变为 0, 此时的 VAE 事实上就退化成了 auto-encoder。 因此我们需要在 Loss 中加入对分布的限制, 从而达到较好的生成效果。</p>\n<h2 id=\"公式推导\"><a href=\"#公式推导\" class=\"headerlink\" title=\"公式推导\"></a>公式推导</h2><p>我们的目标是求解</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/maximum.png\"></div>\n\n\n<p>这个式子可以进行变换:</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/trans.png\"></div>\n\n<p>于是我们得到了一个 logP(x)的下界:</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Lb.png\"></div>\n\n<p>此时原式化为: </p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/yuanshi.png\"></div>\n\n<p>这里要补充一点，当我们在优化 Lb 的时候, KL散度是像0趋近的，这样我们logP(x)就会接近优化的下界。</p>\n<p>注意到 </p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/lbtuidao.png\"></div>\n\n\n<p>因此只需要构造两个求解器，分别是 Encoder 和 Decoder</p>\n<p>其中 Encoder 求解的是 q(z|x) 的分布，我们希望所有的 q(z|x) 都能近似 p(z) 的分布。z 的分布在 VAE 中定义成 N(0, 1)</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Encoder.jpg\"></div>\n\n<p>Decoder 求解的是 p(x|z) 的分布</p>\n<div align=center><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Decoder.jpg\"></div>\n\n\n<p>至此证明完毕</p>\n"},{"title":"使用yfinance获取美股数据的时报错","date":"2022-07-13T02:42:19.000Z","_content":"\n报错信息:\n`No data found for this date range, symbol may be delisted`\n\n开始以为是股票信息出了问题，之后找到原因是大陆不能访问雅虎财经了，所以使用 yf.download时需要添加代理访问。\n\n作者给出了添加代理的方法\n\n```python\nimport yfinance as yf\n\nmsft = yf.Ticker(\"MSFT\")\n\nmsft.history(..., proxy=\"PROXY_SERVER\")\nmsft.get_actions(proxy=\"PROXY_SERVER\")\nmsft.get_dividends(proxy=\"PROXY_SERVER\")\nmsft.get_splits(proxy=\"PROXY_SERVER\")\nmsft.get_balance_sheet(proxy=\"PROXY_SERVER\")\nmsft.get_cashflow(proxy=\"PROXY_SERVER\")\nmsft.option_chain(..., proxy=\"PROXY_SERVER\")\n```\n\n具体代码\n\n```python\nstock_price = yf.download(\"AAPL\", start=\"2017-01-01\", end=\"2017-04-30\", proxy=\"http://127.0.0.1:7890\")\n```\n\n这个代理地址是我的vpn的端口，问题解决\n","source":"_posts/使用yfinance获取美股数据的时报错.md","raw":"---\ntitle: 使用yfinance获取美股数据的时报错\ndate: 2022-07-13 10:42:19\ntags: \n  - 智能投顾\ncategories:\n  - 实验室\n---\n\n报错信息:\n`No data found for this date range, symbol may be delisted`\n\n开始以为是股票信息出了问题，之后找到原因是大陆不能访问雅虎财经了，所以使用 yf.download时需要添加代理访问。\n\n作者给出了添加代理的方法\n\n```python\nimport yfinance as yf\n\nmsft = yf.Ticker(\"MSFT\")\n\nmsft.history(..., proxy=\"PROXY_SERVER\")\nmsft.get_actions(proxy=\"PROXY_SERVER\")\nmsft.get_dividends(proxy=\"PROXY_SERVER\")\nmsft.get_splits(proxy=\"PROXY_SERVER\")\nmsft.get_balance_sheet(proxy=\"PROXY_SERVER\")\nmsft.get_cashflow(proxy=\"PROXY_SERVER\")\nmsft.option_chain(..., proxy=\"PROXY_SERVER\")\n```\n\n具体代码\n\n```python\nstock_price = yf.download(\"AAPL\", start=\"2017-01-01\", end=\"2017-04-30\", proxy=\"http://127.0.0.1:7890\")\n```\n\n这个代理地址是我的vpn的端口，问题解决\n","slug":"使用yfinance获取美股数据的时报错","published":1,"updated":"2022-07-13T02:50:11.123Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl5j08mab0000woyz7nzwddmb","content":"<p>报错信息:<br><code>No data found for this date range, symbol may be delisted</code></p>\n<p>开始以为是股票信息出了问题，之后找到原因是大陆不能访问雅虎财经了，所以使用 yf.download时需要添加代理访问。</p>\n<p>作者给出了添加代理的方法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> yfinance <span class=\"hljs-keyword\">as</span> yf<br><br>msft = yf.Ticker(<span class=\"hljs-string\">&quot;MSFT&quot;</span>)<br><br>msft.history(..., proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br>msft.get_actions(proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br>msft.get_dividends(proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br>msft.get_splits(proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br>msft.get_balance_sheet(proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br>msft.get_cashflow(proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br>msft.option_chain(..., proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<p>具体代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">stock_price = yf.download(<span class=\"hljs-string\">&quot;AAPL&quot;</span>, start=<span class=\"hljs-string\">&quot;2017-01-01&quot;</span>, end=<span class=\"hljs-string\">&quot;2017-04-30&quot;</span>, proxy=<span class=\"hljs-string\">&quot;http://127.0.0.1:7890&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<p>这个代理地址是我的vpn的端口，问题解决</p>\n","site":{"data":{}},"wordcount":696,"excerpt":"","more":"<p>报错信息:<br><code>No data found for this date range, symbol may be delisted</code></p>\n<p>开始以为是股票信息出了问题，之后找到原因是大陆不能访问雅虎财经了，所以使用 yf.download时需要添加代理访问。</p>\n<p>作者给出了添加代理的方法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> yfinance <span class=\"hljs-keyword\">as</span> yf<br><br>msft = yf.Ticker(<span class=\"hljs-string\">&quot;MSFT&quot;</span>)<br><br>msft.history(..., proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br>msft.get_actions(proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br>msft.get_dividends(proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br>msft.get_splits(proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br>msft.get_balance_sheet(proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br>msft.get_cashflow(proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br>msft.option_chain(..., proxy=<span class=\"hljs-string\">&quot;PROXY_SERVER&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<p>具体代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">stock_price = yf.download(<span class=\"hljs-string\">&quot;AAPL&quot;</span>, start=<span class=\"hljs-string\">&quot;2017-01-01&quot;</span>, end=<span class=\"hljs-string\">&quot;2017-04-30&quot;</span>, proxy=<span class=\"hljs-string\">&quot;http://127.0.0.1:7890&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<p>这个代理地址是我的vpn的端口，问题解决</p>\n"},{"title":"Generative Adversarial Network(GAN)学习笔记","author":"boss","date":"2022-07-18T10:22:04.000Z","_content":"\n# Generative Adversarial Network(GAN)学习笔记\n\n重度参考李宏毅老师的课程:\n\nhttps://www.youtube.com/watch?v=4OWp0wDu6Xw&list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J&index=14&ab_channel=Hung-yiLee\n\n## 直观理解\n\n从理解的角度来讲, GAN 由一个生成器和一个判别器组成。训练的过程就是生成器和判别器对抗的过程。判别器希望能分别出生成器生成的图片和真实的图片。而生成器则希望\"以假乱真\", 使最终的判别器无法区分真实的图片和生成的图片。理想的情况下，最终的判别器具有很高的辨认能力, 而生成器生成的图片则几乎无法与真实图片区分。\n\n<div align=\"center\" size=\"80%\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/zhiguanlijie.png\" width=\"80%\", heigt=\"80%\"></div>\n\n&emsp;\n\n比如一开始判别器会学习到真实图片都有眼睛, 这样生成器就会学习生成眼睛的能力, 之后判别器又会学习到真实的头像都有嘴巴, 生成器为了以假乱真也要学会生成嘴巴, 这就是一个对抗的过程, 最终使生成器具有生成能力。\n\n## 训练过程\n\n训练过程很清晰, 首先固定生成器的参数, 对判别器进行训练。 之后固定判别器的参数, 对生成器进行训练。这样迭代多轮后直到训练结束。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/algorithm1.png\" width=\"80%\", heigt=\"80%\"></div>\n\n## 理论介绍\n\n### 目标函数\n\n我们现在有一个生成器 G, 我们最终的目标就是希望 G 生成的分布和真实 Data 的分布是相似的。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/theoryimage.png\" width=\"80%\", heigt=\"80%\"></div>\n\n&emsp;\n\n写成公式就是下面的式子:\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/theoryshizi.png\" width=\"40%\", heigt=\"70%\"></div>\n\n### 求解分布 Diversity\n\n而问题在于, 我们有什么方法能求得这两个分布之间的 Diversity?\n\n首先我们肯定没法直接去求分布的积分，因此可以采样。\n\n一个比较直观的想法是用判别器去对采样的结果进行分类，如果分类准确率高就说明两者的分布相差大,好分辨。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/zhiguanbianbie.png\" width=\"80%\", heigt=\"80%\"></div>          \n&emsp;\n\n公式化的写法就是我们要训练一个判别器, 而 V(G,D) 推导出来事实上就是两个分布间的 JS 散度。我们想要判别器的效果好, 就是要最大化 V。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/bianbieqi.png\" width=\"80%\", heigt=\"80%\"></div>\n\n&emsp;\n\n从另一个角度看, V 其实是交叉熵的负数, 因此我们要最大化 V, 也就是减小判别器的 Loss。\n\n因为 V 越大，代表判别的准确度越高, 因此回到上面的式子, 最小化 Diversity, 也就是最小化 V。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/zuixiaohua.png\" width=\"40%\", heigt=\"80%\"></div>\n\n## GAN 的缺陷\n\n### JS 散度的局限性\n\n可以看到, 我们在上面的公式中使用了 JS 散度来比较两个分布的相似度, 但这会带来问题, 因为 JS 散度没法评估两个不重合分布的相似度。\n\n### 为什么两个分布不重合\n\n#### 1. 数据的性质\n图片的分布在高维空间中可能是一条线, 或者只有很小一部分,这是因为大部分的空间中的点并不能组成一个完整的图像。因此两个分布只会有很少的部分相交, 可以忽略不记。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/fenbuxiangjiao.png\" width=\"45%\", heigt=\"45%\"></div>\n\n#### 2. 采样\n从分布中采样出的点是很少一部分, 即使整体分布有重合，采样的稀疏点也很容易被判别成两个不重合的分布。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/sample.png\" width=\"45%\", heigt=\"45%\"></div>\n\n### JS 散度的问题\n\n只要两个分布不重合, JS 散度恒为 log2, 这就导致判别器没法训练。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/jsproblem.png\" width=\"80%\", heigt=\"80%\"></div>\n\n## Wasserstein distance(推土机距离)\n\n为了解决这个问题, 我们改用 Wasserstein distance 来判断两个分布的相似度。这个距离的定义就是把一个分布变成另一个分布需要移动的最小平均距离。\n\n可以看到, 此时分布间的距离就会越来越近了。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/wdistance.png\" width=\"80%\", heigt=\"80%\"></div>\n\n## WGAN\n\n### 距离公式\nWasserstein distance 也有对应的推导式子:\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/wshizi.png\" width=\"60%\", heigt=\"80%\"></div>\n\n&emsp;\n\n可以看到, 这里对 D 有一个限制, 直白的说就是要求 D 是平滑的。\n\n因为如果没有限制, D 就无法收敛了。(两个值会无限的增大和减小)\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/shoulian.png\"width=\"60%\", heigt=\"60%\" ></div>\n\n### Lipschitz Function\n事实上 D 是要满足这个 Function 的性质, 也就是下面这个式子:\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/Lip.png\"width=\"40%\", heigt=\"40%\" ></div>\n\n而 D 就是 K = 1 的情况。\n\n\n### 如何保证 D 是平滑的\n\n有几种方法使 D 拥有平滑的性质:\n\n* Original WGAN → Weight\n\n    可以限制 w 的值在 [-c, c] 之间, 这样相当于限制了 D 的上下界。\n\n* Improved WGAN → Gradient Penalty\n\n    上面的 Lipschitz 性质有一个等价条件, 就是 D 对 x 的梯度都是小于等于 1 的\n\n    <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/gp.png\"width=\"40%\", heigt=\"40%\" ></div>\n\n    很容易理解的方法就是对梯度加一个惩罚项。\n\n    <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/jifen1.png\" width=\"40%\", heigt=\"40%\" ></div>\n\n    有一个问题在于我们没法对所有的X进行积分, 因此一个替代的方法是用 P<sub>data</sub> 和 P<sub>G</sub> 中间的 P<sub>penalty</sub> 的分布下的 X 作为惩罚项。\n    \n    <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/ppen.png\" width=\"60%\", heigt=\"60%\" ></div>\n\n    这样做看起来也确实是有一定道理的。 因为最终 P<sub>data</sub> 和 P<sub>G</sub> 逐渐靠近, 也只有他们中间的分布才会有影响。\n\n    实验中有一个更好的收敛方法是梯度接近 1 是最好的。\n    <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/improve.png\" width=\"60%\", heigt=\"60%\" ></div>\n\n    https://arxiv.org/abs/1704.00028\n\n* Spectral Normalization → Keep gradient norm smaller than 1 everywhere\n\n    这个方法可以保证每个梯度都是小于 1 的\n\n    https://arxiv.org/abs/1802.05957\n\n### WGAN algorithm\n\nWGAN 的算法在原始 GAN 的只需要四步改进:\n\n* 修改 D 的目标函数\n\n* D 的训练添加 Weight clipping / Gradient Penalty\n\n* 修改 G 的目标函数\n\n* D 的输出不要 sigmoid 激活函数\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/wgan.png\" width=\"90%\", heigt=\"90%\" ></div>\n\n    ","source":"_posts/Generative-Adversarial-Network-GAN-学习笔记.md","raw":"title: Generative Adversarial Network(GAN)学习笔记\nauthor: boss\ndate: 2022-07-18 18:22:04\ntags:\n - GAN\n - 深度学习\ncategories:\n - 实验室\n---\n\n# Generative Adversarial Network(GAN)学习笔记\n\n重度参考李宏毅老师的课程:\n\nhttps://www.youtube.com/watch?v=4OWp0wDu6Xw&list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J&index=14&ab_channel=Hung-yiLee\n\n## 直观理解\n\n从理解的角度来讲, GAN 由一个生成器和一个判别器组成。训练的过程就是生成器和判别器对抗的过程。判别器希望能分别出生成器生成的图片和真实的图片。而生成器则希望\"以假乱真\", 使最终的判别器无法区分真实的图片和生成的图片。理想的情况下，最终的判别器具有很高的辨认能力, 而生成器生成的图片则几乎无法与真实图片区分。\n\n<div align=\"center\" size=\"80%\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/zhiguanlijie.png\" width=\"80%\", heigt=\"80%\"></div>\n\n&emsp;\n\n比如一开始判别器会学习到真实图片都有眼睛, 这样生成器就会学习生成眼睛的能力, 之后判别器又会学习到真实的头像都有嘴巴, 生成器为了以假乱真也要学会生成嘴巴, 这就是一个对抗的过程, 最终使生成器具有生成能力。\n\n## 训练过程\n\n训练过程很清晰, 首先固定生成器的参数, 对判别器进行训练。 之后固定判别器的参数, 对生成器进行训练。这样迭代多轮后直到训练结束。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/algorithm1.png\" width=\"80%\", heigt=\"80%\"></div>\n\n## 理论介绍\n\n### 目标函数\n\n我们现在有一个生成器 G, 我们最终的目标就是希望 G 生成的分布和真实 Data 的分布是相似的。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/theoryimage.png\" width=\"80%\", heigt=\"80%\"></div>\n\n&emsp;\n\n写成公式就是下面的式子:\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/theoryshizi.png\" width=\"40%\", heigt=\"70%\"></div>\n\n### 求解分布 Diversity\n\n而问题在于, 我们有什么方法能求得这两个分布之间的 Diversity?\n\n首先我们肯定没法直接去求分布的积分，因此可以采样。\n\n一个比较直观的想法是用判别器去对采样的结果进行分类，如果分类准确率高就说明两者的分布相差大,好分辨。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/zhiguanbianbie.png\" width=\"80%\", heigt=\"80%\"></div>          \n&emsp;\n\n公式化的写法就是我们要训练一个判别器, 而 V(G,D) 推导出来事实上就是两个分布间的 JS 散度。我们想要判别器的效果好, 就是要最大化 V。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/bianbieqi.png\" width=\"80%\", heigt=\"80%\"></div>\n\n&emsp;\n\n从另一个角度看, V 其实是交叉熵的负数, 因此我们要最大化 V, 也就是减小判别器的 Loss。\n\n因为 V 越大，代表判别的准确度越高, 因此回到上面的式子, 最小化 Diversity, 也就是最小化 V。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/zuixiaohua.png\" width=\"40%\", heigt=\"80%\"></div>\n\n## GAN 的缺陷\n\n### JS 散度的局限性\n\n可以看到, 我们在上面的公式中使用了 JS 散度来比较两个分布的相似度, 但这会带来问题, 因为 JS 散度没法评估两个不重合分布的相似度。\n\n### 为什么两个分布不重合\n\n#### 1. 数据的性质\n图片的分布在高维空间中可能是一条线, 或者只有很小一部分,这是因为大部分的空间中的点并不能组成一个完整的图像。因此两个分布只会有很少的部分相交, 可以忽略不记。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/fenbuxiangjiao.png\" width=\"45%\", heigt=\"45%\"></div>\n\n#### 2. 采样\n从分布中采样出的点是很少一部分, 即使整体分布有重合，采样的稀疏点也很容易被判别成两个不重合的分布。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/sample.png\" width=\"45%\", heigt=\"45%\"></div>\n\n### JS 散度的问题\n\n只要两个分布不重合, JS 散度恒为 log2, 这就导致判别器没法训练。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/jsproblem.png\" width=\"80%\", heigt=\"80%\"></div>\n\n## Wasserstein distance(推土机距离)\n\n为了解决这个问题, 我们改用 Wasserstein distance 来判断两个分布的相似度。这个距离的定义就是把一个分布变成另一个分布需要移动的最小平均距离。\n\n可以看到, 此时分布间的距离就会越来越近了。\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/wdistance.png\" width=\"80%\", heigt=\"80%\"></div>\n\n## WGAN\n\n### 距离公式\nWasserstein distance 也有对应的推导式子:\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/wshizi.png\" width=\"60%\", heigt=\"80%\"></div>\n\n&emsp;\n\n可以看到, 这里对 D 有一个限制, 直白的说就是要求 D 是平滑的。\n\n因为如果没有限制, D 就无法收敛了。(两个值会无限的增大和减小)\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/shoulian.png\"width=\"60%\", heigt=\"60%\" ></div>\n\n### Lipschitz Function\n事实上 D 是要满足这个 Function 的性质, 也就是下面这个式子:\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/Lip.png\"width=\"40%\", heigt=\"40%\" ></div>\n\n而 D 就是 K = 1 的情况。\n\n\n### 如何保证 D 是平滑的\n\n有几种方法使 D 拥有平滑的性质:\n\n* Original WGAN → Weight\n\n    可以限制 w 的值在 [-c, c] 之间, 这样相当于限制了 D 的上下界。\n\n* Improved WGAN → Gradient Penalty\n\n    上面的 Lipschitz 性质有一个等价条件, 就是 D 对 x 的梯度都是小于等于 1 的\n\n    <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/gp.png\"width=\"40%\", heigt=\"40%\" ></div>\n\n    很容易理解的方法就是对梯度加一个惩罚项。\n\n    <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/jifen1.png\" width=\"40%\", heigt=\"40%\" ></div>\n\n    有一个问题在于我们没法对所有的X进行积分, 因此一个替代的方法是用 P<sub>data</sub> 和 P<sub>G</sub> 中间的 P<sub>penalty</sub> 的分布下的 X 作为惩罚项。\n    \n    <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/ppen.png\" width=\"60%\", heigt=\"60%\" ></div>\n\n    这样做看起来也确实是有一定道理的。 因为最终 P<sub>data</sub> 和 P<sub>G</sub> 逐渐靠近, 也只有他们中间的分布才会有影响。\n\n    实验中有一个更好的收敛方法是梯度接近 1 是最好的。\n    <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/improve.png\" width=\"60%\", heigt=\"60%\" ></div>\n\n    https://arxiv.org/abs/1704.00028\n\n* Spectral Normalization → Keep gradient norm smaller than 1 everywhere\n\n    这个方法可以保证每个梯度都是小于 1 的\n\n    https://arxiv.org/abs/1802.05957\n\n### WGAN algorithm\n\nWGAN 的算法在原始 GAN 的只需要四步改进:\n\n* 修改 D 的目标函数\n\n* D 的训练添加 Weight clipping / Gradient Penalty\n\n* 修改 G 的目标函数\n\n* D 的输出不要 sigmoid 激活函数\n\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/wgan.png\" width=\"90%\", heigt=\"90%\" ></div>\n\n    ","slug":"Generative-Adversarial-Network-GAN-学习笔记","published":1,"updated":"2022-07-19T08:53:28.023Z","_id":"cl5qlj54v0000t4yz7pz5dnmk","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"Generative-Adversarial-Network-GAN-学习笔记\"><a href=\"#Generative-Adversarial-Network-GAN-学习笔记\" class=\"headerlink\" title=\"Generative Adversarial Network(GAN)学习笔记\"></a>Generative Adversarial Network(GAN)学习笔记</h1><p>重度参考李宏毅老师的课程:</p>\n<p><a href=\"https://www.youtube.com/watch?v=4OWp0wDu6Xw&amp;list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J&amp;index=14&amp;ab_channel=Hung-yiLee\">https://www.youtube.com/watch?v=4OWp0wDu6Xw&amp;list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J&amp;index=14&amp;ab_channel=Hung-yiLee</a></p>\n<h2 id=\"直观理解\"><a href=\"#直观理解\" class=\"headerlink\" title=\"直观理解\"></a>直观理解</h2><p>从理解的角度来讲, GAN 由一个生成器和一个判别器组成。训练的过程就是生成器和判别器对抗的过程。判别器希望能分别出生成器生成的图片和真实的图片。而生成器则希望”以假乱真”, 使最终的判别器无法区分真实的图片和生成的图片。理想的情况下，最终的判别器具有很高的辨认能力, 而生成器生成的图片则几乎无法与真实图片区分。</p>\n<div align=\"center\" size=\"80%\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/zhiguanlijie.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<p>&emsp;</p>\n<p>比如一开始判别器会学习到真实图片都有眼睛, 这样生成器就会学习生成眼睛的能力, 之后判别器又会学习到真实的头像都有嘴巴, 生成器为了以假乱真也要学会生成嘴巴, 这就是一个对抗的过程, 最终使生成器具有生成能力。</p>\n<h2 id=\"训练过程\"><a href=\"#训练过程\" class=\"headerlink\" title=\"训练过程\"></a>训练过程</h2><p>训练过程很清晰, 首先固定生成器的参数, 对判别器进行训练。 之后固定判别器的参数, 对生成器进行训练。这样迭代多轮后直到训练结束。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/algorithm1.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<h2 id=\"理论介绍\"><a href=\"#理论介绍\" class=\"headerlink\" title=\"理论介绍\"></a>理论介绍</h2><h3 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h3><p>我们现在有一个生成器 G, 我们最终的目标就是希望 G 生成的分布和真实 Data 的分布是相似的。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/theoryimage.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<p>&emsp;</p>\n<p>写成公式就是下面的式子:</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/theoryshizi.png\" width=\"40%\", heigt=\"70%\"></div>\n\n<h3 id=\"求解分布-Diversity\"><a href=\"#求解分布-Diversity\" class=\"headerlink\" title=\"求解分布 Diversity\"></a>求解分布 Diversity</h3><p>而问题在于, 我们有什么方法能求得这两个分布之间的 Diversity?</p>\n<p>首先我们肯定没法直接去求分布的积分，因此可以采样。</p>\n<p>一个比较直观的想法是用判别器去对采样的结果进行分类，如果分类准确率高就说明两者的分布相差大,好分辨。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/zhiguanbianbie.png\" width=\"80%\", heigt=\"80%\"></div>          \n&emsp;\n\n<p>公式化的写法就是我们要训练一个判别器, 而 V(G,D) 推导出来事实上就是两个分布间的 JS 散度。我们想要判别器的效果好, 就是要最大化 V。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/bianbieqi.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<p>&emsp;</p>\n<p>从另一个角度看, V 其实是交叉熵的负数, 因此我们要最大化 V, 也就是减小判别器的 Loss。</p>\n<p>因为 V 越大，代表判别的准确度越高, 因此回到上面的式子, 最小化 Diversity, 也就是最小化 V。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/zuixiaohua.png\" width=\"40%\", heigt=\"80%\"></div>\n\n<h2 id=\"GAN-的缺陷\"><a href=\"#GAN-的缺陷\" class=\"headerlink\" title=\"GAN 的缺陷\"></a>GAN 的缺陷</h2><h3 id=\"JS-散度的局限性\"><a href=\"#JS-散度的局限性\" class=\"headerlink\" title=\"JS 散度的局限性\"></a>JS 散度的局限性</h3><p>可以看到, 我们在上面的公式中使用了 JS 散度来比较两个分布的相似度, 但这会带来问题, 因为 JS 散度没法评估两个不重合分布的相似度。</p>\n<h3 id=\"为什么两个分布不重合\"><a href=\"#为什么两个分布不重合\" class=\"headerlink\" title=\"为什么两个分布不重合\"></a>为什么两个分布不重合</h3><h4 id=\"1-数据的性质\"><a href=\"#1-数据的性质\" class=\"headerlink\" title=\"1. 数据的性质\"></a>1. 数据的性质</h4><p>图片的分布在高维空间中可能是一条线, 或者只有很小一部分,这是因为大部分的空间中的点并不能组成一个完整的图像。因此两个分布只会有很少的部分相交, 可以忽略不记。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/fenbuxiangjiao.png\" width=\"45%\", heigt=\"45%\"></div>\n\n<h4 id=\"2-采样\"><a href=\"#2-采样\" class=\"headerlink\" title=\"2. 采样\"></a>2. 采样</h4><p>从分布中采样出的点是很少一部分, 即使整体分布有重合，采样的稀疏点也很容易被判别成两个不重合的分布。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/sample.png\" width=\"45%\", heigt=\"45%\"></div>\n\n<h3 id=\"JS-散度的问题\"><a href=\"#JS-散度的问题\" class=\"headerlink\" title=\"JS 散度的问题\"></a>JS 散度的问题</h3><p>只要两个分布不重合, JS 散度恒为 log2, 这就导致判别器没法训练。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/jsproblem.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<h2 id=\"Wasserstein-distance-推土机距离\"><a href=\"#Wasserstein-distance-推土机距离\" class=\"headerlink\" title=\"Wasserstein distance(推土机距离)\"></a>Wasserstein distance(推土机距离)</h2><p>为了解决这个问题, 我们改用 Wasserstein distance 来判断两个分布的相似度。这个距离的定义就是把一个分布变成另一个分布需要移动的最小平均距离。</p>\n<p>可以看到, 此时分布间的距离就会越来越近了。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/wdistance.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<h2 id=\"WGAN\"><a href=\"#WGAN\" class=\"headerlink\" title=\"WGAN\"></a>WGAN</h2><h3 id=\"距离公式\"><a href=\"#距离公式\" class=\"headerlink\" title=\"距离公式\"></a>距离公式</h3><p>Wasserstein distance 也有对应的推导式子:</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/wshizi.png\" width=\"60%\", heigt=\"80%\"></div>\n\n<p>&emsp;</p>\n<p>可以看到, 这里对 D 有一个限制, 直白的说就是要求 D 是平滑的。</p>\n<p>因为如果没有限制, D 就无法收敛了。(两个值会无限的增大和减小)</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/shoulian.png\"width=\"60%\", heigt=\"60%\" ></div>\n\n<h3 id=\"Lipschitz-Function\"><a href=\"#Lipschitz-Function\" class=\"headerlink\" title=\"Lipschitz Function\"></a>Lipschitz Function</h3><p>事实上 D 是要满足这个 Function 的性质, 也就是下面这个式子:</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/Lip.png\"width=\"40%\", heigt=\"40%\" ></div>\n\n<p>而 D 就是 K = 1 的情况。</p>\n<h3 id=\"如何保证-D-是平滑的\"><a href=\"#如何保证-D-是平滑的\" class=\"headerlink\" title=\"如何保证 D 是平滑的\"></a>如何保证 D 是平滑的</h3><p>有几种方法使 D 拥有平滑的性质:</p>\n<ul>\n<li><p>Original WGAN → Weight</p>\n<p>  可以限制 w 的值在 [-c, c] 之间, 这样相当于限制了 D 的上下界。</p>\n</li>\n<li><p>Improved WGAN → Gradient Penalty</p>\n<p>  上面的 Lipschitz 性质有一个等价条件, 就是 D 对 x 的梯度都是小于等于 1 的</p>\n  <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/gp.png\"width=\"40%\", heigt=\"40%\" ></div>\n\n<p>  很容易理解的方法就是对梯度加一个惩罚项。</p>\n  <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/jifen1.png\" width=\"40%\", heigt=\"40%\" ></div>\n\n<p>  有一个问题在于我们没法对所有的X进行积分, 因此一个替代的方法是用 P<sub>data</sub> 和 P<sub>G</sub> 中间的 P<sub>penalty</sub> 的分布下的 X 作为惩罚项。</p>\n  <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/ppen.png\" width=\"60%\", heigt=\"60%\" ></div>\n\n<p>  这样做看起来也确实是有一定道理的。 因为最终 P<sub>data</sub> 和 P<sub>G</sub> 逐渐靠近, 也只有他们中间的分布才会有影响。</p>\n<p>  实验中有一个更好的收敛方法是梯度接近 1 是最好的。</p>\n  <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/improve.png\" width=\"60%\", heigt=\"60%\" ></div>\n\n<p>  <a href=\"https://arxiv.org/abs/1704.00028\">https://arxiv.org/abs/1704.00028</a></p>\n</li>\n<li><p>Spectral Normalization → Keep gradient norm smaller than 1 everywhere</p>\n<p>  这个方法可以保证每个梯度都是小于 1 的</p>\n<p>  <a href=\"https://arxiv.org/abs/1802.05957\">https://arxiv.org/abs/1802.05957</a></p>\n</li>\n</ul>\n<h3 id=\"WGAN-algorithm\"><a href=\"#WGAN-algorithm\" class=\"headerlink\" title=\"WGAN algorithm\"></a>WGAN algorithm</h3><p>WGAN 的算法在原始 GAN 的只需要四步改进:</p>\n<ul>\n<li><p>修改 D 的目标函数</p>\n</li>\n<li><p>D 的训练添加 Weight clipping / Gradient Penalty</p>\n</li>\n<li><p>修改 G 的目标函数</p>\n</li>\n<li><p>D 的输出不要 sigmoid 激活函数</p>\n</li>\n</ul>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/wgan.png\" width=\"90%\", heigt=\"90%\" ></div>\n\n","site":{"data":{}},"wordcount":1961,"excerpt":"","more":"<h1 id=\"Generative-Adversarial-Network-GAN-学习笔记\"><a href=\"#Generative-Adversarial-Network-GAN-学习笔记\" class=\"headerlink\" title=\"Generative Adversarial Network(GAN)学习笔记\"></a>Generative Adversarial Network(GAN)学习笔记</h1><p>重度参考李宏毅老师的课程:</p>\n<p><a href=\"https://www.youtube.com/watch?v=4OWp0wDu6Xw&amp;list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J&amp;index=14&amp;ab_channel=Hung-yiLee\">https://www.youtube.com/watch?v=4OWp0wDu6Xw&amp;list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J&amp;index=14&amp;ab_channel=Hung-yiLee</a></p>\n<h2 id=\"直观理解\"><a href=\"#直观理解\" class=\"headerlink\" title=\"直观理解\"></a>直观理解</h2><p>从理解的角度来讲, GAN 由一个生成器和一个判别器组成。训练的过程就是生成器和判别器对抗的过程。判别器希望能分别出生成器生成的图片和真实的图片。而生成器则希望”以假乱真”, 使最终的判别器无法区分真实的图片和生成的图片。理想的情况下，最终的判别器具有很高的辨认能力, 而生成器生成的图片则几乎无法与真实图片区分。</p>\n<div align=\"center\" size=\"80%\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/zhiguanlijie.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<p>&emsp;</p>\n<p>比如一开始判别器会学习到真实图片都有眼睛, 这样生成器就会学习生成眼睛的能力, 之后判别器又会学习到真实的头像都有嘴巴, 生成器为了以假乱真也要学会生成嘴巴, 这就是一个对抗的过程, 最终使生成器具有生成能力。</p>\n<h2 id=\"训练过程\"><a href=\"#训练过程\" class=\"headerlink\" title=\"训练过程\"></a>训练过程</h2><p>训练过程很清晰, 首先固定生成器的参数, 对判别器进行训练。 之后固定判别器的参数, 对生成器进行训练。这样迭代多轮后直到训练结束。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/algorithm1.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<h2 id=\"理论介绍\"><a href=\"#理论介绍\" class=\"headerlink\" title=\"理论介绍\"></a>理论介绍</h2><h3 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h3><p>我们现在有一个生成器 G, 我们最终的目标就是希望 G 生成的分布和真实 Data 的分布是相似的。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/theoryimage.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<p>&emsp;</p>\n<p>写成公式就是下面的式子:</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/theoryshizi.png\" width=\"40%\", heigt=\"70%\"></div>\n\n<h3 id=\"求解分布-Diversity\"><a href=\"#求解分布-Diversity\" class=\"headerlink\" title=\"求解分布 Diversity\"></a>求解分布 Diversity</h3><p>而问题在于, 我们有什么方法能求得这两个分布之间的 Diversity?</p>\n<p>首先我们肯定没法直接去求分布的积分，因此可以采样。</p>\n<p>一个比较直观的想法是用判别器去对采样的结果进行分类，如果分类准确率高就说明两者的分布相差大,好分辨。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/zhiguanbianbie.png\" width=\"80%\", heigt=\"80%\"></div>          \n&emsp;\n\n<p>公式化的写法就是我们要训练一个判别器, 而 V(G,D) 推导出来事实上就是两个分布间的 JS 散度。我们想要判别器的效果好, 就是要最大化 V。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/bianbieqi.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<p>&emsp;</p>\n<p>从另一个角度看, V 其实是交叉熵的负数, 因此我们要最大化 V, 也就是减小判别器的 Loss。</p>\n<p>因为 V 越大，代表判别的准确度越高, 因此回到上面的式子, 最小化 Diversity, 也就是最小化 V。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/zuixiaohua.png\" width=\"40%\", heigt=\"80%\"></div>\n\n<h2 id=\"GAN-的缺陷\"><a href=\"#GAN-的缺陷\" class=\"headerlink\" title=\"GAN 的缺陷\"></a>GAN 的缺陷</h2><h3 id=\"JS-散度的局限性\"><a href=\"#JS-散度的局限性\" class=\"headerlink\" title=\"JS 散度的局限性\"></a>JS 散度的局限性</h3><p>可以看到, 我们在上面的公式中使用了 JS 散度来比较两个分布的相似度, 但这会带来问题, 因为 JS 散度没法评估两个不重合分布的相似度。</p>\n<h3 id=\"为什么两个分布不重合\"><a href=\"#为什么两个分布不重合\" class=\"headerlink\" title=\"为什么两个分布不重合\"></a>为什么两个分布不重合</h3><h4 id=\"1-数据的性质\"><a href=\"#1-数据的性质\" class=\"headerlink\" title=\"1. 数据的性质\"></a>1. 数据的性质</h4><p>图片的分布在高维空间中可能是一条线, 或者只有很小一部分,这是因为大部分的空间中的点并不能组成一个完整的图像。因此两个分布只会有很少的部分相交, 可以忽略不记。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/fenbuxiangjiao.png\" width=\"45%\", heigt=\"45%\"></div>\n\n<h4 id=\"2-采样\"><a href=\"#2-采样\" class=\"headerlink\" title=\"2. 采样\"></a>2. 采样</h4><p>从分布中采样出的点是很少一部分, 即使整体分布有重合，采样的稀疏点也很容易被判别成两个不重合的分布。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/sample.png\" width=\"45%\", heigt=\"45%\"></div>\n\n<h3 id=\"JS-散度的问题\"><a href=\"#JS-散度的问题\" class=\"headerlink\" title=\"JS 散度的问题\"></a>JS 散度的问题</h3><p>只要两个分布不重合, JS 散度恒为 log2, 这就导致判别器没法训练。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/jsproblem.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<h2 id=\"Wasserstein-distance-推土机距离\"><a href=\"#Wasserstein-distance-推土机距离\" class=\"headerlink\" title=\"Wasserstein distance(推土机距离)\"></a>Wasserstein distance(推土机距离)</h2><p>为了解决这个问题, 我们改用 Wasserstein distance 来判断两个分布的相似度。这个距离的定义就是把一个分布变成另一个分布需要移动的最小平均距离。</p>\n<p>可以看到, 此时分布间的距离就会越来越近了。</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/wdistance.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<h2 id=\"WGAN\"><a href=\"#WGAN\" class=\"headerlink\" title=\"WGAN\"></a>WGAN</h2><h3 id=\"距离公式\"><a href=\"#距离公式\" class=\"headerlink\" title=\"距离公式\"></a>距离公式</h3><p>Wasserstein distance 也有对应的推导式子:</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/wshizi.png\" width=\"60%\", heigt=\"80%\"></div>\n\n<p>&emsp;</p>\n<p>可以看到, 这里对 D 有一个限制, 直白的说就是要求 D 是平滑的。</p>\n<p>因为如果没有限制, D 就无法收敛了。(两个值会无限的增大和减小)</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/shoulian.png\"width=\"60%\", heigt=\"60%\" ></div>\n\n<h3 id=\"Lipschitz-Function\"><a href=\"#Lipschitz-Function\" class=\"headerlink\" title=\"Lipschitz Function\"></a>Lipschitz Function</h3><p>事实上 D 是要满足这个 Function 的性质, 也就是下面这个式子:</p>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/Lip.png\"width=\"40%\", heigt=\"40%\" ></div>\n\n<p>而 D 就是 K = 1 的情况。</p>\n<h3 id=\"如何保证-D-是平滑的\"><a href=\"#如何保证-D-是平滑的\" class=\"headerlink\" title=\"如何保证 D 是平滑的\"></a>如何保证 D 是平滑的</h3><p>有几种方法使 D 拥有平滑的性质:</p>\n<ul>\n<li><p>Original WGAN → Weight</p>\n<p>  可以限制 w 的值在 [-c, c] 之间, 这样相当于限制了 D 的上下界。</p>\n</li>\n<li><p>Improved WGAN → Gradient Penalty</p>\n<p>  上面的 Lipschitz 性质有一个等价条件, 就是 D 对 x 的梯度都是小于等于 1 的</p>\n  <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/gp.png\"width=\"40%\", heigt=\"40%\" ></div>\n\n<p>  很容易理解的方法就是对梯度加一个惩罚项。</p>\n  <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/jifen1.png\" width=\"40%\", heigt=\"40%\" ></div>\n\n<p>  有一个问题在于我们没法对所有的X进行积分, 因此一个替代的方法是用 P<sub>data</sub> 和 P<sub>G</sub> 中间的 P<sub>penalty</sub> 的分布下的 X 作为惩罚项。</p>\n  <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/ppen.png\" width=\"60%\", heigt=\"60%\" ></div>\n\n<p>  这样做看起来也确实是有一定道理的。 因为最终 P<sub>data</sub> 和 P<sub>G</sub> 逐渐靠近, 也只有他们中间的分布才会有影响。</p>\n<p>  实验中有一个更好的收敛方法是梯度接近 1 是最好的。</p>\n  <div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/improve.png\" width=\"60%\", heigt=\"60%\" ></div>\n\n<p>  <a href=\"https://arxiv.org/abs/1704.00028\">https://arxiv.org/abs/1704.00028</a></p>\n</li>\n<li><p>Spectral Normalization → Keep gradient norm smaller than 1 everywhere</p>\n<p>  这个方法可以保证每个梯度都是小于 1 的</p>\n<p>  <a href=\"https://arxiv.org/abs/1802.05957\">https://arxiv.org/abs/1802.05957</a></p>\n</li>\n</ul>\n<h3 id=\"WGAN-algorithm\"><a href=\"#WGAN-algorithm\" class=\"headerlink\" title=\"WGAN algorithm\"></a>WGAN algorithm</h3><p>WGAN 的算法在原始 GAN 的只需要四步改进:</p>\n<ul>\n<li><p>修改 D 的目标函数</p>\n</li>\n<li><p>D 的训练添加 Weight clipping / Gradient Penalty</p>\n</li>\n<li><p>修改 G 的目标函数</p>\n</li>\n<li><p>D 的输出不要 sigmoid 激活函数</p>\n</li>\n</ul>\n<div align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/dontnet-wuenze/picbed/Generative Adversarial Network(GAN)/wgan.png\" width=\"90%\", heigt=\"90%\" ></div>\n\n"},{"title":"VAE-GAN 结合 论文梳理","author":"boss","date":"2022-07-19T08:52:00.000Z","_content":"\n# VAE-GAN 结合 论文梳理\n\n## 回顾\n\n## 论文梳理\n\n### VAE-GAN\n\n\n[[2016][ICML]Autoencoding beyond pixels using a learned similarity metric-VAE-GANs](https://arxiv.org/abs/1512.09300)\n\n这篇论文模型的结构就是连接了 VAE 和 GAN。\n\n<div align=\"center\" size=\"80%\"><img src=\".\\VAE-GAN 结合\\VAE-GAN.png\" width=\"80%\", heigt=\"80%\"></div>\n\n&emsp;\n\n#### 不同视角\n\n- VAE视角 : 判别器具有 GAN 的性质, 生成图像更真实, 弥补 VAE 生成图像模糊的缺点。\n\n- GAN视角: 需要额外计算 VAE 的重构 loss, 提升了模型的稳定性。\n\n#### 训练过程\n\n<div>\n- 训练 Encoder 来降低降低生成 $$\\tilde{x}$$ 与 真实 $$x$$差距 $$\\left|| \\tilde{x} - x|\\right| $$, 即降低 $KL(P(\\tilde{z}|x)||p(z))$ \n</div>\n","source":"_posts/VAE-GAN-结合-论文梳理.md","raw":"title: VAE-GAN 结合 论文梳理\nauthor: boss\ndate: 2022-07-19 16:52:00\ntags:\n - GAN\n - VAE\n - 深度学习\ncategories: \n - 实验室\n---\n\n# VAE-GAN 结合 论文梳理\n\n## 回顾\n\n## 论文梳理\n\n### VAE-GAN\n\n\n[[2016][ICML]Autoencoding beyond pixels using a learned similarity metric-VAE-GANs](https://arxiv.org/abs/1512.09300)\n\n这篇论文模型的结构就是连接了 VAE 和 GAN。\n\n<div align=\"center\" size=\"80%\"><img src=\".\\VAE-GAN 结合\\VAE-GAN.png\" width=\"80%\", heigt=\"80%\"></div>\n\n&emsp;\n\n#### 不同视角\n\n- VAE视角 : 判别器具有 GAN 的性质, 生成图像更真实, 弥补 VAE 生成图像模糊的缺点。\n\n- GAN视角: 需要额外计算 VAE 的重构 loss, 提升了模型的稳定性。\n\n#### 训练过程\n\n<div>\n- 训练 Encoder 来降低降低生成 $$\\tilde{x}$$ 与 真实 $$x$$差距 $$\\left|| \\tilde{x} - x|\\right| $$, 即降低 $KL(P(\\tilde{z}|x)||p(z))$ \n</div>\n","slug":"VAE-GAN-结合-论文梳理","published":1,"updated":"2022-07-19T10:51:30.921Z","_id":"cl5rxsudd0000lgyzd89a0iei","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"VAE-GAN-结合-论文梳理\"><a href=\"#VAE-GAN-结合-论文梳理\" class=\"headerlink\" title=\"VAE-GAN 结合 论文梳理\"></a>VAE-GAN 结合 论文梳理</h1><h2 id=\"回顾\"><a href=\"#回顾\" class=\"headerlink\" title=\"回顾\"></a>回顾</h2><h2 id=\"论文梳理\"><a href=\"#论文梳理\" class=\"headerlink\" title=\"论文梳理\"></a>论文梳理</h2><h3 id=\"VAE-GAN\"><a href=\"#VAE-GAN\" class=\"headerlink\" title=\"VAE-GAN\"></a>VAE-GAN</h3><p><a href=\"https://arxiv.org/abs/1512.09300\">[2016][ICML]Autoencoding beyond pixels using a learned similarity metric-VAE-GANs</a></p>\n<p>这篇论文模型的结构就是连接了 VAE 和 GAN。</p>\n<div align=\"center\" size=\"80%\"><img src=\".\\VAE-GAN 结合\\VAE-GAN.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<p>&emsp;</p>\n<h4 id=\"不同视角\"><a href=\"#不同视角\" class=\"headerlink\" title=\"不同视角\"></a>不同视角</h4><ul>\n<li><p>VAE视角 : 判别器具有 GAN 的性质, 生成图像更真实, 弥补 VAE 生成图像模糊的缺点。</p>\n</li>\n<li><p>GAN视角: 需要额外计算 VAE 的重构 loss, 提升了模型的稳定性。</p>\n</li>\n</ul>\n<h4 id=\"训练过程\"><a href=\"#训练过程\" class=\"headerlink\" title=\"训练过程\"></a>训练过程</h4><div>\n- 训练 Encoder 来降低降低生成 $$\\tilde{x}$$ 与 真实 $$x$$差距 $$\\left|| \\tilde{x} - x|\\right| $$, 即降低 $KL(P(\\tilde{z}|x)||p(z))$ \n</div>\n","site":{"data":{}},"wordcount":310,"excerpt":"","more":"<h1 id=\"VAE-GAN-结合-论文梳理\"><a href=\"#VAE-GAN-结合-论文梳理\" class=\"headerlink\" title=\"VAE-GAN 结合 论文梳理\"></a>VAE-GAN 结合 论文梳理</h1><h2 id=\"回顾\"><a href=\"#回顾\" class=\"headerlink\" title=\"回顾\"></a>回顾</h2><h2 id=\"论文梳理\"><a href=\"#论文梳理\" class=\"headerlink\" title=\"论文梳理\"></a>论文梳理</h2><h3 id=\"VAE-GAN\"><a href=\"#VAE-GAN\" class=\"headerlink\" title=\"VAE-GAN\"></a>VAE-GAN</h3><p><a href=\"https://arxiv.org/abs/1512.09300\">[2016][ICML]Autoencoding beyond pixels using a learned similarity metric-VAE-GANs</a></p>\n<p>这篇论文模型的结构就是连接了 VAE 和 GAN。</p>\n<div align=\"center\" size=\"80%\"><img src=\".\\VAE-GAN 结合\\VAE-GAN.png\" width=\"80%\", heigt=\"80%\"></div>\n\n<p>&emsp;</p>\n<h4 id=\"不同视角\"><a href=\"#不同视角\" class=\"headerlink\" title=\"不同视角\"></a>不同视角</h4><ul>\n<li><p>VAE视角 : 判别器具有 GAN 的性质, 生成图像更真实, 弥补 VAE 生成图像模糊的缺点。</p>\n</li>\n<li><p>GAN视角: 需要额外计算 VAE 的重构 loss, 提升了模型的稳定性。</p>\n</li>\n</ul>\n<h4 id=\"训练过程\"><a href=\"#训练过程\" class=\"headerlink\" title=\"训练过程\"></a>训练过程</h4><div>\n- 训练 Encoder 来降低降低生成 $$\\tilde{x}$$ 与 真实 $$x$$差距 $$\\left|| \\tilde{x} - x|\\right| $$, 即降低 $KL(P(\\tilde{z}|x)||p(z))$ \n</div>\n"}],"PostAsset":[{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/Decoder.jpg","slug":"Decoder.jpg","post":"cl5i15m700000n0yz51h5hjz5","modified":0,"renderable":0},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/Encoder.jpg","slug":"Encoder.jpg","post":"cl5i15m700000n0yz51h5hjz5","modified":0,"renderable":0},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/Lb.png","slug":"Lb.png","post":"cl5i15m700000n0yz51h5hjz5","modified":0,"renderable":0},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/lbtuidao.png","slug":"lbtuidao.png","post":"cl5i15m700000n0yz51h5hjz5","modified":0,"renderable":0},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/maximum.png","slug":"maximum.png","post":"cl5i15m700000n0yz51h5hjz5","modified":0,"renderable":0},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/model.jpg","slug":"model.jpg","post":"cl5i15m700000n0yz51h5hjz5","modified":0,"renderable":0},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/noise.jpg","slug":"noise.jpg","post":"cl5i15m700000n0yz51h5hjz5","modified":0,"renderable":0},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/trans.png","slug":"trans.png","post":"cl5i15m700000n0yz51h5hjz5","modified":0,"renderable":0},{"_id":"source/_posts/VAE-Auto-Encoding-Variational-Bayes-学习笔记/yuanshi.png","slug":"yuanshi.png","post":"cl5i15m700000n0yz51h5hjz5","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cl5f1mjj60003eoyzb4wad629","category_id":"cl5f1mjjb0004eoyzfo03ewum","_id":"cl5f1mjje0007eoyz8h3pc52f"},{"post_id":"cl5fh6o970001moyzbvhnc8ff","category_id":"cl5fh8nlc0003moyz0wd77czi","_id":"cl5fh8nld0005moyz0i75fitn"},{"post_id":"cl5i15m700000n0yz51h5hjz5","category_id":"cl5i15m7x0001n0yzh3ue7pzu","_id":"cl5i15m800004n0yz86nkhghe"},{"post_id":"cl5j08mab0000woyz7nzwddmb","category_id":"cl5i15m7x0001n0yzh3ue7pzu","_id":"cl5j08mbd0002woyz5tz7eoa0"},{"post_id":"cl5qlj54v0000t4yz7pz5dnmk","category_id":"cl5i15m7x0001n0yzh3ue7pzu","_id":"cl5rxusds0001lgyzhjyd6ab4"},{"post_id":"cl5rxsudd0000lgyzd89a0iei","category_id":"cl5i15m7x0001n0yzh3ue7pzu","_id":"cl5rxuwab0004lgyz2quqcldq"}],"PostTag":[{"post_id":"cl5f1mjj60003eoyzb4wad629","tag_id":"cl5f1mjjc0005eoyz8rw1dwin","_id":"cl5f1mjjd0006eoyzc5hgepe4"},{"post_id":"cl5fh6o970001moyzbvhnc8ff","tag_id":"cl5fh8nlb0002moyzhr3e7mvs","_id":"cl5fh8nlc0004moyzh5fvcg3j"},{"post_id":"cl5i15m700000n0yz51h5hjz5","tag_id":"cl5i15m7z0003n0yzejg3d716","_id":"cl5i15m810007n0yz8kpi57e6"},{"post_id":"cl5i15m700000n0yz51h5hjz5","tag_id":"cl5i15m800005n0yzha75ersv","_id":"cl5i15m810008n0yz22fw4cqf"},{"post_id":"cl5j08mab0000woyz7nzwddmb","tag_id":"cl5j08mbb0001woyz2hse9u1k","_id":"cl5j08mbe0003woyzd8zd0p24"},{"post_id":"cl5i15m700000n0yz51h5hjz5","tag_id":"cl5qllc2x0001t4yz76ci3wom","_id":"cl5qllc2y0002t4yz1vk93sv1"},{"post_id":"cl5qlj54v0000t4yz7pz5dnmk","tag_id":"cl5qllxle0003t4yza6cjevsk","_id":"cl5qllxlf0004t4yz0d2j8r6m"},{"post_id":"cl5qlj54v0000t4yz7pz5dnmk","tag_id":"cl5i15m7z0003n0yzejg3d716","_id":"cl5qllxlf0005t4yz7rp5dk5j"},{"post_id":"cl5rxsudd0000lgyzd89a0iei","tag_id":"cl5qllxle0003t4yza6cjevsk","_id":"cl5rxuwab0002lgyz68j8h0e1"},{"post_id":"cl5rxsudd0000lgyzd89a0iei","tag_id":"cl5qllc2x0001t4yz76ci3wom","_id":"cl5rxuwab0003lgyz8vp48chm"},{"post_id":"cl5rxsudd0000lgyzd89a0iei","tag_id":"cl5i15m7z0003n0yzejg3d716","_id":"cl5rxuwab0005lgyz25a5hzdr"}],"Tag":[{"name":"原创","_id":"cl5f1mjjc0005eoyz8rw1dwin"},{"name":"CMU 149","_id":"cl5fh8nlb0002moyzhr3e7mvs"},{"name":"VAE ","_id":"cl5i15m7z0002n0yzf9ufh7gi"},{"name":"深度学习","_id":"cl5i15m7z0003n0yzejg3d716"},{"name":"笔记","_id":"cl5i15m800005n0yzha75ersv"},{"name":"智能投顾","_id":"cl5j08mbb0001woyz2hse9u1k"},{"name":"VAE","_id":"cl5qllc2x0001t4yz76ci3wom"},{"name":"GAN","_id":"cl5qllxle0003t4yza6cjevsk"}]}}